

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>07. Speed up computations with parallel_compute() &mdash; pyUSID 0.0.4 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="08. Utilities that assist in writing USID data" href="plot_write_utils.html" />
    <link rel="prev" title="06. Utilities for handling data types and transformations" href="plot_dtype_utils.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> pyUSID
          

          
          </a>

          
            
            
              <div class="version">
                0.0.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about.html">pyUSID</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../external_guides.html">Tutorials on Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package_organization.html">Package Organization</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples &amp; Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#guides-to-pyusid">Guides to pyUSID</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_h5py.html">01. Primer to HDF5 and h5py</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_usi_dataset.html">02. The USIDataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_numpy_translator.html">03. Translation and the NumpyTranslator</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_plot_utils.html">04. Plotting utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_hdf_utils_read.html">05. Utilities for reading h5USID files</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_dtype_utils.html">06. Utilities for handling data types and transformations</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">07. Speed up computations with parallel_compute()</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-scientific-problem">Example scientific problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-the-dataset">Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-operation">The operation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#testing-the-function">Testing the function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#serial-computing">Serial computing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pyusid-parallel-compute">pyUSID.parallel_compute()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compare-the-results">Compare the results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#simplifying-the-function">Simplifying the function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#more-cores">More cores!</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scalability">Scalability</a></li>
<li class="toctree-l4"><a class="reference internal" href="#best-practices-for-parallel-computing">Best practices for parallel computing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#formalizing-data-processing-and-pyusid-process">Formalizing data processing and pyUSID.Process</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_write_utils.html">08. Utilities that assist in writing USID data</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_hdf_utils_write.html">09. Utilities for writing h5USID files</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_process.html">10. Formalizing Data Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_io_utils.html">11. Input / Output / Computing utilities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../data_format.html">Data Model and File Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribution_guidelines.html">Guidelines for Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../credits.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../whats_new.html">What’s New</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../matlab_to_python.html">Upgrading from Matlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pyUSID</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Examples &amp; Tutorials</a> &raquo;</li>
        
      <li>07. Speed up computations with parallel_compute()</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/auto_examples/cookbooks/plot_parallel_compute.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-auto-examples-cookbooks-plot-parallel-compute-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="speed-up-computations-with-parallel-compute">
<span id="sphx-glr-auto-examples-cookbooks-plot-parallel-compute-py"></span><h1>07. Speed up computations with parallel_compute()<a class="headerlink" href="#speed-up-computations-with-parallel-compute" title="Permalink to this headline">¶</a></h1>
<p><strong>Suhas Somnath, Chris R. Smith</strong></p>
<p>9/8/2017</p>
<p><strong>This document will demonstrate how ``pyUSID.parallel_compute()`` can significantly speed up data processing by
using all available CPU cores in a computer</strong></p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Quite often, we need to perform the same operation on every single component in our data. One of the most popular
examples is functional fitting applied to spectra collected at each location on a grid. While, the operation itself
may not take very long, computing this operation thousands of times, once per location, using a single CPU core can
take a long time to complete. Most personal computers today come with at least two cores, and in many cases, each of
these cores is represented via two logical cores, thereby summing to a total of at least four cores. Thus, it is
prudent to make use of these unused cores whenever possible. Fortunately, there are a few python packages that
facilitate the efficient use of all CPU cores with minimal modifications to the existing code.</p>
<p><code class="docutils literal notranslate"><span class="pre">pyUSID.parallel_compute()</span></code> is a very handy function that simplifies parallel computation significantly to a
<code class="docutils literal notranslate"><span class="pre">single</span> <span class="pre">function</span> <span class="pre">call</span></code> and will be discussed in this document.</p>
</div>
<div class="section" id="example-scientific-problem">
<h2>Example scientific problem<a class="headerlink" href="#example-scientific-problem" title="Permalink to this headline">¶</a></h2>
<p>For this example, we will be working with a <code class="docutils literal notranslate"><span class="pre">Band</span> <span class="pre">Excitation</span> <span class="pre">Piezoresponse</span> <span class="pre">Force</span> <span class="pre">Microscopy</span> <span class="pre">(BE-PFM)</span></code> imaging dataset
acquired from advanced atomic force microscopes. In this dataset, a spectra was collected for each position in a two
dimensional grid of spatial locations. Thus, this is a three dimensional dataset that has been flattened to a two
dimensional matrix in accordance with <strong>Universal Spectroscopy and Imaging Data (USID)</strong> model.</p>
<p>Each spectra in this dataset is expected to have a single peak. The goal is to find the positions of the peaks in each
spectra. Clearly, the operation of finding the peak in one spectra is independent of the same operation on another
spectra. Thus, we could in theory divide the dataset in to N parts and use N CPU cores to compute the results much
faster than it would take a single core to compute the results. There is an important caveat to this statement and it
will be discussed at the end of this document.</p>
<p><code class="docutils literal notranslate"><span class="pre">Here,</span> <span class="pre">we</span> <span class="pre">will</span> <span class="pre">learn</span> <span class="pre">how</span> <span class="pre">to</span> <span class="pre">fit</span> <span class="pre">the</span> <span class="pre">thousands</span> <span class="pre">of</span> <span class="pre">spectra</span> <span class="pre">using</span> <span class="pre">all</span> <span class="pre">available</span> <span class="pre">cores</span> <span class="pre">on</span> <span class="pre">a</span> <span class="pre">computer.</span></code>
Note, that this is applicable only for a single CPU. Please refer to another advanced example for multi-CPU computing.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ensure python 3 compatibility:</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">unicode_literals</span>

<span class="c1"># The package for accessing files in directories, etc.:</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Warning package in case something goes wrong</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="k">def</span> <span class="nf">install</span><span class="p">(</span><span class="n">package</span><span class="p">):</span>
    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;pip&quot;</span><span class="p">,</span> <span class="s2">&quot;install&quot;</span><span class="p">,</span> <span class="n">package</span><span class="p">])</span>
<span class="c1"># Package for downloading online files:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="c1"># This package is not part of anaconda and may need to be installed.</span>
    <span class="kn">import</span> <span class="nn">wget</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;wget not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="n">wget</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">wget</span>

<span class="c1"># The mathematical computation package:</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># The package used for creating and manipulating HDF5 files:</span>
<span class="kn">import</span> <span class="nn">h5py</span>

<span class="c1"># Packages for plotting:</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># Parallel computation library:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">joblib</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;joblib not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;joblib&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">joblib</span>

<span class="c1"># Timing</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># A handy python utility that allows us to preconfigure parts of a function</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># Finally import pyUSID:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pyUSID</span> <span class="kn">as</span> <span class="nn">usid</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;pyUSID not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;pyUSID&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pyUSID</span> <span class="kn">as</span> <span class="nn">usid</span>

<span class="c1"># import the scientific function:</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;./supporting_docs/&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">peak_finding</span> <span class="kn">import</span> <span class="n">find_all_peaks</span>
</pre></div>
</div>
</div>
<div class="section" id="load-the-dataset">
<h2>Load the dataset<a class="headerlink" href="#load-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>In order to demonstrate parallel computing, we will be using a real experimental dataset that is available on the
pyUSID GitHub project. First, lets download this file from Github:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_path</span> <span class="o">=</span> <span class="s1">&#39;temp.h5&#39;</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/pycroscopy/pyUSID/master/data/BELine_0004.h5&#39;</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">h5_path</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">h5_path</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">h5_path</span><span class="p">,</span> <span class="n">bar</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, lets open this HDF5 file. The focus of this example is not on the data storage or arrangement but rather on
demonstrating parallel computation so lets dive straight into the main dataset that requires fitting of the spectra:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Open the file in read-only mode</span>
<span class="n">h5_file</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="c1"># Get handle to the the raw data</span>
<span class="n">h5_meas_grp</span> <span class="o">=</span> <span class="n">h5_file</span><span class="p">[</span><span class="s1">&#39;Measurement_000&#39;</span><span class="p">]</span>

<span class="c1"># Accessing the dataset of interest:</span>
<span class="n">h5_main</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">USIDataset</span><span class="p">(</span><span class="n">h5_meas_grp</span><span class="p">[</span><span class="s1">&#39;Channel_000/Raw_Data&#39;</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">The main dataset:</span><span class="se">\n</span><span class="s1">------------------------------------&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_main</span><span class="p">)</span>

<span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span> <span class="o">=</span> <span class="n">h5_main</span><span class="o">.</span><span class="n">pos_dim_sizes</span>
<span class="n">cores_vec</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">times_vec</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The main dataset:
------------------------------------
&lt;HDF5 dataset &quot;Raw_Data&quot;: shape (16384, 119), type &quot;&lt;c8&quot;&gt;
located at:
        /Measurement_000/Channel_000/Raw_Data
Data contains:
        Cantilever Vertical Deflection (V)
Data dimensions and original shape:
Position Dimensions:
        X - size: 128
        Y - size: 128
Spectroscopic Dimensions:
        Frequency - size: 119
Data Type:
        complex64
</pre></div>
</div>
</div>
<div class="section" id="the-operation">
<h2>The operation<a class="headerlink" href="#the-operation" title="Permalink to this headline">¶</a></h2>
<p>The scipy package has a very handy function called <em>find_peaks_cwt()</em> that facilitates the search for one or more
peaks in a spectrum. We will be using a function called <em>find_all_peaks()</em> that uses <em>find_peaks_cwt()</em>.
For the purposes of this example, we do not be concerned with how this
function works. All we need to know is that this function takes 3 inputs:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">vector</span></code> - a 1D array containing the spectra at a single location</li>
<li><code class="docutils literal notranslate"><span class="pre">width_bounds</span></code> - something like [20, 50] that instructs the function to look for peaks that are 20-50
data-points wide. The function will look for a peak with width of 20, then again for a peak of width - 21 and so on.</li>
<li><code class="docutils literal notranslate"><span class="pre">num_steps</span></code> - The number of steps within the possible widths [20, 50], that the search must be performed</li>
</ul>
<p>The function has one output:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">peak_indices</span></code> - an array of the positions at which peaks were found.</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">find_all_peaks</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">width_bounds</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the function that will be mapped by multiprocess. This is a wrapper around the scipy function.</span>
<span class="sd">    It uses a parameter - wavelet_widths that is configured outside this function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vector : 1D numpy array</span>
<span class="sd">        Feature vector containing peaks</span>
<span class="sd">    width_bounds : tuple / list / iterable</span>
<span class="sd">        Min and max for the size of the window</span>
<span class="sd">    num_steps : uint, (optional). Default = 20</span>
<span class="sd">        Number of different peak widths to search</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    peak_indices : list</span>
<span class="sd">        List of indices of peaks within the prescribed peak widths</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># The below numpy array is used to configure the returned function wpeaks</span>
    <span class="n">wavelet_widths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">width_bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width_bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_steps</span><span class="p">)</span>

    <span class="n">peak_indices</span> <span class="o">=</span> <span class="n">find_peaks_cwt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vector</span><span class="p">),</span> <span class="n">wavelet_widths</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">peak_indices</span>
</pre></div>
</div>
</div>
<div class="section" id="testing-the-function">
<h2>Testing the function<a class="headerlink" href="#testing-the-function" title="Permalink to this headline">¶</a></h2>
<p>Let’s see what the operation on an example spectra returns.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span> <span class="o">=</span> <span class="mi">103</span><span class="p">,</span> <span class="mi">19</span>
<span class="n">pixel_ind</span> <span class="o">=</span> <span class="n">col_ind</span> <span class="o">+</span> <span class="n">row_ind</span> <span class="o">*</span> <span class="n">num_cols</span>
<span class="n">spectra</span> <span class="o">=</span> <span class="n">h5_main</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]</span>

<span class="n">peak_inds</span> <span class="o">=</span> <span class="n">find_all_peaks</span><span class="p">(</span><span class="n">spectra</span><span class="p">,</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">],</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">()</span>
<span class="n">axis</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">spectra</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">peak_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">))]);</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;find_all_peaks found peaks at index: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">peak_inds</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_parallel_compute_001.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_parallel_compute_001.png" />
<p>Before we apply the function to the entire dataset, lets load the dataset to memory so that file-loading time is not a
factor when comparing the times for serial and parallel computing times:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">raw_data</span> <span class="o">=</span> <span class="n">h5_main</span><span class="p">[()]</span>
</pre></div>
</div>
</div>
<div class="section" id="serial-computing">
<h2>Serial computing<a class="headerlink" href="#serial-computing" title="Permalink to this headline">¶</a></h2>
<p>A single call to the function does not take substantial time. However, performing the same operation on each of the
<code class="docutils literal notranslate"><span class="pre">16,384</span></code> pixels sequentially can take substantial time. The simplest way to find all peak positions is to simply loop
over each position in the dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">serial_results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">t_0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">vector</span> <span class="ow">in</span> <span class="n">raw_data</span><span class="p">:</span>
    <span class="n">serial_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">find_all_peaks</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">],</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">))</span>
<span class="n">times_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t_0</span><span class="p">)</span>
<span class="n">cores_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Serial computation took&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">times_vec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39; seconds&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Serial computation took 58.97  seconds
</pre></div>
</div>
</div>
<div class="section" id="pyusid-parallel-compute">
<h2>pyUSID.parallel_compute()<a class="headerlink" href="#pyusid-parallel-compute" title="Permalink to this headline">¶</a></h2>
<p>There are several libraries that can utilize multiple CPU cores to perform the same computation in parallel. Popular
examples are <code class="docutils literal notranslate"><span class="pre">Multiprocessing</span></code>, <code class="docutils literal notranslate"><span class="pre">Mutiprocess</span></code>, <code class="docutils literal notranslate"><span class="pre">Dask</span></code>, <code class="docutils literal notranslate"><span class="pre">Joblib</span></code> etc. Each of these has their own
strengths and weaknesses. Some of them have painful caveats such as the inability to perform the parallel computation
within a jupyter notebook. In order to lower the barrier to parallel computation, we have developed a very handy
function called <code class="docutils literal notranslate"><span class="pre">pyUSID.parallel_compute()</span></code> that simplifies the process to a single function call.</p>
<p>It is a lot <strong>more straightforward</strong> to provide the arguments and keyword arguments of the function that needs to be
applied to the entire dataset. Furthermore, this function intelligently assigns the number of CPU cores for the
parallel computation based on the size of the dataset and the computational complexity of the unit computation.
For instance, it scales down the number of cores for small datasets if each computation is short. It also ensures that
1-2 cores fewer than all available cores are used by default so that the user can continue using their computer for
other purposes while the computation runs.</p>
<p>Lets apply this <code class="docutils literal notranslate"><span class="pre">parallel_compute</span></code> to this problem:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cpu_cores</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">args</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">]]</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;num_steps&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>

<span class="n">t_0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Execute the parallel computation</span>
<span class="n">parallel_results</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">parallel_compute</span><span class="p">(</span><span class="n">raw_data</span><span class="p">,</span> <span class="n">find_all_peaks</span><span class="p">,</span> <span class="n">cores</span><span class="o">=</span><span class="n">cpu_cores</span><span class="p">,</span> <span class="n">func_args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">func_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">cores_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cpu_cores</span><span class="p">)</span>
<span class="n">times_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t_0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Parallel computation with {} cores took {} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpu_cores</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">times_vec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Starting computing on 2 cores (requested 2 cores)
Finished parallel computation
Parallel computation with 2 cores took 35.68 seconds
</pre></div>
</div>
</div>
<div class="section" id="compare-the-results">
<h2>Compare the results<a class="headerlink" href="#compare-the-results" title="Permalink to this headline">¶</a></h2>
<p>By comparing the run-times for the two approaches, we see that the parallel computation is substantially faster than
the serial computation. Note that the numbers will differ between computers. Also, the computation was performed on
a relatively small dataset for illustrative purposes. The benefits of using such parallel computation will be far
more apparent for much larger datasets.</p>
<p>Let’s compare the results from both the serial and parallel methods to ensure they give the same results:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Result from serial computation: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">serial_results</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Result from parallel computation: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">parallel_results</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Result from serial computation: [62]
Result from parallel computation: [62]
</pre></div>
</div>
</div>
<div class="section" id="simplifying-the-function">
<h2>Simplifying the function<a class="headerlink" href="#simplifying-the-function" title="Permalink to this headline">¶</a></h2>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">width_bounds</span></code> and <code class="docutils literal notranslate"><span class="pre">num_steps</span></code> arguments will not be changed from one pixel to another. It would be
great if we didn’t have to keep track of these constant arguments. We can use a very handy python tool called
<code class="docutils literal notranslate"><span class="pre">partial()</span></code> to do just this. Below, all we are doing is creating a new function that always passes our preferred
values for <code class="docutils literal notranslate"><span class="pre">width_bounds</span></code> and <code class="docutils literal notranslate"><span class="pre">num_steps</span></code> arguments to find_all_peaks. While it may seem like this is unimportant,
it is very convenient when setting up the parallel computing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">find_peaks</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">find_all_peaks</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">width_bounds</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">])</span>
</pre></div>
</div>
<p>Notice that even though <code class="docutils literal notranslate"><span class="pre">width_bounds</span></code> is an argument, it needs to be specified as though it were a keyword argument
like <code class="docutils literal notranslate"><span class="pre">num_steps</span></code>.
Let’s try calling our simplified function, <code class="docutils literal notranslate"><span class="pre">find_peaks()</span></code> to make sure that it results in the same peak index for the
aforementioned chosen spectra:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;find_peaks found peaks at index: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">find_peaks</span><span class="p">(</span><span class="n">h5_main</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">])))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>find_peaks found peaks at index: [62]
</pre></div>
</div>
</div>
<div class="section" id="more-cores">
<h2>More cores!<a class="headerlink" href="#more-cores" title="Permalink to this headline">¶</a></h2>
<p>Lets use <code class="docutils literal notranslate"><span class="pre">find_peaks()</span></code> instead of <code class="docutils literal notranslate"><span class="pre">find_all_peaks</span></code> on the entire dataset but increase the number of cores to 3.
Note that we do not need to specify <code class="docutils literal notranslate"><span class="pre">func_kwargs</span></code> anymore. Also note that this is a very simple function and the
benefits of <code class="docutils literal notranslate"><span class="pre">partial()</span></code> will be greater for more complex problems.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cpu_cores</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">t_0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Execute the parallel computation</span>
<span class="n">parallel_results</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">parallel_compute</span><span class="p">(</span><span class="n">raw_data</span><span class="p">,</span> <span class="n">find_peaks</span><span class="p">,</span> <span class="n">cores</span><span class="o">=</span><span class="n">cpu_cores</span><span class="p">)</span>

<span class="n">cores_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cpu_cores</span><span class="p">)</span>
<span class="n">times_vec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t_0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Parallel computation with {} cores took {} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpu_cores</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">times_vec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Starting computing on 3 cores (requested 3 cores)
Finished parallel computation
Parallel computation with 3 cores took 36.81 seconds
</pre></div>
</div>
</div>
<div class="section" id="scalability">
<h2>Scalability<a class="headerlink" href="#scalability" title="Permalink to this headline">¶</a></h2>
<p>Now lets see how the computational time relates to the number of cores.
Depending on your computer (and what was running on your computer along with this computation), you are likely to see
diminishing benefits of additional cores beyond 2 cores for this specific problem in the plot below. This is because
the dataset is relatively small and each peak-finding operation is relatively quick. The overhead of adding additional
cores quickly outweighs the speedup in distributing the work among multiple CPU cores.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">))</span>
<span class="n">axis</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cores_vec</span><span class="p">,</span> <span class="n">times_vec</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;CPU cores&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Compute time (sec)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_parallel_compute_002.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_parallel_compute_002.png" />
</div>
<div class="section" id="best-practices-for-parallel-computing">
<h2>Best practices for parallel computing<a class="headerlink" href="#best-practices-for-parallel-computing" title="Permalink to this headline">¶</a></h2>
<p>While it may seem tempting to do everything in parallel, it is important to be aware of some of the trade-offs and
best-practices for parallel computing (multiple CPU cores) when compared to traditional serial computing (single
CPU core):</p>
<ul class="simple">
<li>There is noticeable time overhead involved with setting up each parallel computing job. For very simple or small
computations, this overhead may outweigh the speed-up gained with using multiple cores.</li>
<li>Parallelizing computations that read and write to files at each iteration may be actually be noticeably <em>slower</em>
than serial computation since each core will compete with all other cores for rights to read and write to the file(s)
and these input/output operations are by far the slowest components of the computation. Instead, it makes sense to
read large amounts of data from the necessary files once, perform the computation, and then write to the files once
after all the computation is complete. In fact, this is what we automatically do in the <code class="docutils literal notranslate"><span class="pre">Fitter</span></code> and
<code class="docutils literal notranslate"><span class="pre">Process</span></code> classes in pycroscopy</li>
</ul>
</div>
<div class="section" id="formalizing-data-processing-and-pyusid-process">
<h2>Formalizing data processing and pyUSID.Process<a class="headerlink" href="#formalizing-data-processing-and-pyusid-process" title="Permalink to this headline">¶</a></h2>
<p>Data processing / analysis typically involves a few basic operations:</p>
<ol class="arabic simple">
<li>Reading data from file</li>
<li>Parallel computation</li>
<li>Writing results to disk</li>
</ol>
<p>The Process class in pyUSID has modularized these operations for simpler and faster development of standardized,
easy-to-debug code. In the case of this example, one would only need to write the find_all_peaks() function along with
the appropriate data reading and data writing functions. Other common operations can be inherited from
pyUSID.Process.</p>
<p>Please see another example on how to write a Process class for pyUSID based on this example</p>
<p>Lets not forget to close and delete the temporarily downloaded file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">h5_path</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 2 minutes  13.189 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-cookbooks-plot-parallel-compute-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_parallel_compute.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_parallel_compute.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_parallel_compute.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_parallel_compute.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="plot_write_utils.html" class="btn btn-neutral float-right" title="08. Utilities that assist in writing USID data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="plot_dtype_utils.html" class="btn btn-neutral" title="06. Utilities for handling data types and transformations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Suhas Somnath, Chris R. Smith, Stephen Jesse.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.0.4',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>