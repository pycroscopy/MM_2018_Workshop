

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>09. Utilities for writing h5USID files &mdash; pyUSID 0.0.4 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="10. Formalizing Data Processing" href="plot_process.html" />
    <link rel="prev" title="08. Utilities that assist in writing USID data" href="plot_write_utils.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> pyUSID
          

          
          </a>

          
            
            
              <div class="version">
                0.0.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about.html">pyUSID</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../external_guides.html">Tutorials on Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package_organization.html">Package Organization</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples &amp; Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#guides-to-pyusid">Guides to pyUSID</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_h5py.html">01. Primer to HDF5 and h5py</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_usi_dataset.html">02. The USIDataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_numpy_translator.html">03. Translation and the NumpyTranslator</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_plot_utils.html">04. Plotting utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_hdf_utils_read.html">05. Utilities for reading h5USID files</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_dtype_utils.html">06. Utilities for handling data types and transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_parallel_compute.html">07. Speed up computations with parallel_compute()</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_write_utils.html">08. Utilities that assist in writing USID data</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">09. Utilities for writing h5USID files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#recommended-pre-requisite-reading">Recommended pre-requisite reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-all-necessary-packages">Import all necessary packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hdf-utils-works-with-and-uses-h5py">HDF_Utils works with (and uses) h5py</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-indexed-group">create_indexed_group()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write-book-keeping-attrs">write_book_keeping_attrs()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write-simple-attrs">write_simple_attrs()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#copy-attributes">copy_attributes()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-up-a-toy-problem">Set up a toy problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#specify-position-and-spectroscopic-dimensions">Specify position and spectroscopic dimensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write-main-dataset">write_main_dataset()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#populating-the-dataset">Populating the Dataset:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#exploring-attributes-in-main-datasets">Exploring attributes in Main datasets:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#link-h5-objects-as-attrs">link_h5_objects_as_attrs()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#link-h5-obj-as-alias">link_h5_obj_as_alias()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-results-group">create_results_group()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#writing-the-main-dataset">Writing the main dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shared-ancillary-datasets">Shared ancillary datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-empty-dataset">create_empty_dataset()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write-reduced-spec-dsets">write_reduced_spec_dsets()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write-ind-val-dsets">write_ind_val_dsets()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#is-editable-h5">is_editable_h5()</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_process.html">10. Formalizing Data Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_io_utils.html">11. Input / Output / Computing utilities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../data_format.html">Data Model and File Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribution_guidelines.html">Guidelines for Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../credits.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../whats_new.html">What’s New</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../matlab_to_python.html">Upgrading from Matlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pyUSID</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Examples &amp; Tutorials</a> &raquo;</li>
        
      <li>09. Utilities for writing h5USID files</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/auto_examples/cookbooks/plot_hdf_utils_write.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-auto-examples-cookbooks-plot-hdf-utils-write-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="utilities-for-writing-h5usid-files">
<span id="sphx-glr-auto-examples-cookbooks-plot-hdf-utils-write-py"></span><h1>09. Utilities for writing h5USID files<a class="headerlink" href="#utilities-for-writing-h5usid-files" title="Permalink to this headline">¶</a></h1>
<p><strong>Suhas Somnath</strong></p>
<p>4/18/2018</p>
<p><strong>This document illustrates the many handy functions in pyUSID.hdf_utils that significantly simplify writing data
and information into Universal Spectroscopy and Imaging Data (USID) HDF5 files (h5USID files)</strong></p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The USID model uses a data-centric approach to data analysis and processing meaning that results from all data analysis
and processing are written to the same h5 file that contains the recorded measurements. The Hierarchical Data Format
(HDF5) allows data, whether it is raw measured data or results of analysis, to be stored in multiple datasets within
the same file in a tree-like manner. Certain rules and considerations have been made in pyUSID to ensure
consistent and easy access to any data.</p>
<p>The h5py python package provides great functions to create, read, and manage data in HDF5 files. In
<code class="docutils literal notranslate"><span class="pre">pyUSID.hdf_utils</span></code>, we have added functions that facilitate scientifically relevant, or pyUSID specific
functionality such as easy creation of USID Main datasets, creation of automatically indexed groups to hold
results of an analysis, etc. Due to the wide breadth of the functions in <code class="docutils literal notranslate"><span class="pre">hdf_utils</span></code>, the guide for hdf_utils will be
split in two parts - one that focuses on functions that facilitate reading and one that facilitate writing of data.
The following guide provides examples of how, and more importantly when, to use functions in pyUSID.hdf_utils for
various scenarios starting from recording data from instruments to storing analysis data.</p>
</div>
<div class="section" id="recommended-pre-requisite-reading">
<h2>Recommended pre-requisite reading<a class="headerlink" href="#recommended-pre-requisite-reading" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="/../../data_format.html">USID data model</a></li>
<li><a class="reference external" href="./plot_h5py.html">Crash course on HDF5 and h5py</a></li>
<li>Utilities for <a class="reference external" href="./plot_hdf_utils_read.html">reading</a> h5USID files using pyUSID</li>
</ul>
</div>
<div class="section" id="import-all-necessary-packages">
<h2>Import all necessary packages<a class="headerlink" href="#import-all-necessary-packages" title="Permalink to this headline">¶</a></h2>
<p>Before we begin demonstrating the numerous functions in pyUSID.hdf_utils, we need to import the necessary
packages. Here are a list of packages besides pyUSID that will be used in this example:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">h5py</span></code> - to open and close the file</li>
<li><code class="docutils literal notranslate"><span class="pre">numpy</span></code> - for numerical operations on arrays in memory</li>
<li><code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> - basic visualization of data</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">unicode_literals</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="k">def</span> <span class="nf">install</span><span class="p">(</span><span class="n">package</span><span class="p">):</span>
    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;pip&quot;</span><span class="p">,</span> <span class="s2">&quot;install&quot;</span><span class="p">,</span> <span class="n">package</span><span class="p">])</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="c1"># Warning package in case something goes wrong</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># Finally import pyUSID.</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pyUSID</span> <span class="kn">as</span> <span class="nn">usid</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;pyUSID not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;pyUSID&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pyUSID</span> <span class="kn">as</span> <span class="nn">usid</span>
</pre></div>
</div>
<div class="section" id="create-a-hdf5-file">
<h3>Create a HDF5 file<a class="headerlink" href="#create-a-hdf5-file" title="Permalink to this headline">¶</a></h3>
<p>We will be using the h5py functionality to do basic operations on HDF5 files</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">file_path</span> <span class="o">=</span> <span class="s1">&#39;test.h5&#39;</span>
<span class="n">h5_file</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="hdf-utils-works-with-and-uses-h5py">
<h2>HDF_Utils works with (and uses) h5py<a class="headerlink" href="#hdf-utils-works-with-and-uses-h5py" title="Permalink to this headline">¶</a></h2>
<p>pyUSID and <code class="docutils literal notranslate"><span class="pre">hdf_utils</span></code> do not preclude the creation of groups and datasets using the <code class="docutils literal notranslate"><span class="pre">h5py</span></code> package. However, the
many functions in <code class="docutils literal notranslate"><span class="pre">hdf_utils</span></code> are present to make it easier to handle the reading and writing of multidimensional
scientific data formatted according to the USID model.</p>
<p>We can always use the <code class="docutils literal notranslate"><span class="pre">h5py</span></code> functionality to <strong>create a HDF5 group</strong> as shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_some_group</span> <span class="o">=</span> <span class="n">h5_file</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;Some_Group&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_some_group</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 group &quot;/Some_Group&quot; (0 members)&gt;
</pre></div>
</div>
<p>In the same way, we can also continue to <strong>create HDF5 datasets</strong> using h5py:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_some_dataset</span> <span class="o">=</span> <span class="n">h5_some_group</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;Some_Dataset&#39;</span><span class="p">,</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_some_dataset</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Some_Dataset&quot;: shape (0, 1, 2, 3, 4), type &quot;&lt;f4&quot;&gt;
</pre></div>
</div>
<div class="section" id="create-groups">
<h3>Create Groups<a class="headerlink" href="#create-groups" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="create-indexed-group">
<h2>create_indexed_group()<a class="headerlink" href="#create-indexed-group" title="Permalink to this headline">¶</a></h2>
<p>In order to accommodate the iterative nature of data recording (multiple sequential and related measurements) and
analysis (same analysis performed with different parameters) we add an index as a suffix to HDF5 Group names.</p>
<p>Let us first create a HDF5 group to store some data recorded from an instrument. The below function will automatically
create a group with an index as a suffix and write certain book-keeping attributes to the group. We will see how this
and similar functions handle situations when similarly named groups already exist.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_meas_group</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">create_indexed_group</span><span class="p">(</span><span class="n">h5_file</span><span class="p">,</span> <span class="s1">&#39;Measurement&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_meas_group</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 group &quot;/Measurement_000&quot; (0 members)&gt;
</pre></div>
</div>
<p>Since there were no other groups whose name started with <code class="docutils literal notranslate"><span class="pre">Measurement</span></code>, the function assigned the lowest index - <code class="docutils literal notranslate"><span class="pre">000</span></code>
as a suffix to the requested group name.
Note that the <code class="docutils literal notranslate"><span class="pre">-</span></code> character is not allowed in the names of the groups since it will be used as the separator character
in other functions. This will be made clear when discussing the <code class="docutils literal notranslate"><span class="pre">create_results_group()</span></code> function later.</p>
<p><code class="docutils literal notranslate"><span class="pre">create_indexed_group()</span></code> calls another handy function called <code class="docutils literal notranslate"><span class="pre">assign_group_index(</span></code> to get the suffix before creating a
HDF5 group. Should we want to create another new indexed group called <code class="docutils literal notranslate"><span class="pre">Measurement</span></code>, <code class="docutils literal notranslate"><span class="pre">assign_group_index()</span></code> will
notice that a group named <code class="docutils literal notranslate"><span class="pre">Measurement_000</span></code> already exists and will assign the next index (<code class="docutils literal notranslate"><span class="pre">001</span></code>) to the new group -
see below. Note that <code class="docutils literal notranslate"><span class="pre">assign_group_index()</span></code> does not create the group; it only assigns a non-conflicting string name
for the group.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">assign_group_index</span><span class="p">(</span><span class="n">h5_file</span><span class="p">,</span> <span class="s1">&#39;Measurement&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Measurement_001
</pre></div>
</div>
<p>Now lets look at datasets and groups in the created file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Contents within the file so far:&#39;</span><span class="p">)</span>
<span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Contents within the file so far:
/
├ Measurement_000
  ---------------
├ Some_Group
  ----------
  ├ Some_Dataset
</pre></div>
</div>
<p>Clearly, we have the <code class="docutils literal notranslate"><span class="pre">Measurement_000</span></code> Group at the same level as a group named <code class="docutils literal notranslate"><span class="pre">Some_Group</span></code>. The group <code class="docutils literal notranslate"><span class="pre">Some_Group</span></code>
contains a dataset named <code class="docutils literal notranslate"><span class="pre">Some_Dataset</span></code> under it.</p>
<p>Both, <code class="docutils literal notranslate"><span class="pre">Measurement_000</span></code> and <code class="docutils literal notranslate"><span class="pre">Some_Group</span></code> have an underline below their name to indicate that they are groups unlike
the <code class="docutils literal notranslate"><span class="pre">Some_Dataset</span></code> Dataset</p>
<div class="section" id="writing-attributes">
<h3>Writing attributes<a class="headerlink" href="#writing-attributes" title="Permalink to this headline">¶</a></h3>
<p>HDF5 datasets and groups can also store metadata such as experimental parameters. These metadata can be text,
numbers, small lists of numbers or text etc. These metadata can be very important for understanding the datasets
and guide the analysis routines.</p>
<p>While one could use the basic h5py functionality to write and access attributes, one would encounter a lot of problems
when attempting to encode or decode attributes whose values were strings or lists of strings due to some issues in
h5py. This problem has been demonstrated in our
<cite>primer to HDF5 &lt;./plot_h5py.html&gt;</cite>. Instead of using
the basic functionality of <code class="docutils literal notranslate"><span class="pre">h5py</span></code>, we recommend always using the functions in pyUSID that <strong>work reliably and
consistently</strong> for any kind of attribute for any version of python:</p>
<p>Here’s a look at the (self-explanatory), default attributes that will be written to the indexed group for traceability
and posterity. Note that we are using pyUSID’s <code class="docutils literal notranslate"><span class="pre">get_attributes()</span></code> function instead of the base h5py capability</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Attributes contained within {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">h5_meas_group</span><span class="p">))</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_meas_group</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="si">%s</span><span class="s1"> : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Attributes contained within &lt;HDF5 group &quot;/Measurement_000&quot; (0 members)&gt;
        machine_id : challtdow-Aspire-F5-573G
        timestamp : 2018_07_31-13_16_15
        pyUSID_version : 0.0.4
        platform : Linux-4.15.0-29-generic-x86_64-with-debian-stretch-sid
</pre></div>
</div>
<p>Note that these book-keeping attributes written by <code class="docutils literal notranslate"><span class="pre">create_indexed_group()</span></code> are not written when using h5py’s
<code class="docutils literal notranslate"><span class="pre">create_group()</span></code> function to create a regular group.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Attributes contained in the basic group created using h5py: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">h5_some_group</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_some_group</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Attributes contained in the basic group created using h5py: &lt;HDF5 group &quot;/Some_Group&quot; (1 members)&gt;
{}
</pre></div>
</div>
</div>
</div>
<div class="section" id="write-book-keeping-attrs">
<h2>write_book_keeping_attrs()<a class="headerlink" href="#write-book-keeping-attrs" title="Permalink to this headline">¶</a></h2>
<p>However, you can always manually add these basic attributes after creating the group using the
<code class="docutils literal notranslate"><span class="pre">write_book_keeping_attrs()</span></code>. Note that we can add these basic attributes to Datasets as well as Groups using this
function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_book_keeping_attrs</span><span class="p">(</span><span class="n">h5_some_group</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Attributes contained in the basic group after calling write_book_keeping_attrs():&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_some_group</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="si">%s</span><span class="s1"> : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Attributes contained in the basic group after calling write_book_keeping_attrs():
        machine_id : challtdow-Aspire-F5-573G
        timestamp : 2018_07_31-13_16_15
        pyUSID_version : 0.0.4
        platform : Linux-4.15.0-29-generic-x86_64-with-debian-stretch-sid
</pre></div>
</div>
</div>
<div class="section" id="write-simple-attrs">
<h2>write_simple_attrs()<a class="headerlink" href="#write-simple-attrs" title="Permalink to this headline">¶</a></h2>
<p>Due to the problems in h5py, we use the <code class="docutils literal notranslate"><span class="pre">write_simple_attrs()</span></code> function to add / modify additional attributes to the
group:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_simple_attrs</span><span class="p">(</span><span class="n">h5_meas_group</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;Instrument&#39;</span><span class="p">:</span> <span class="s1">&#39;Atomic Force Microscope&#39;</span><span class="p">,</span>
                                                <span class="s1">&#39;User&#39;</span><span class="p">:</span> <span class="s1">&#39;Joe Smith&#39;</span><span class="p">,</span>
                                                <span class="s1">&#39;Room Temperature [C]&#39;</span><span class="p">:</span> <span class="mi">23</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="section" id="copy-attributes">
<h2>copy_attributes()<a class="headerlink" href="#copy-attributes" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">hdf_utils.copy_attributes()</span></code> is another handy function that simplifies the process of copying attributes from one
HDF5 object to another like a Dataset or Group or the file itself. To illustrate, let us copy the attributes from
<code class="docutils literal notranslate"><span class="pre">h5_meas_group</span></code> to <code class="docutils literal notranslate"><span class="pre">h5_some_dataset</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Attributes in {} before copying attributes:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">h5_some_dataset</span><span class="p">))</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_some_dataset</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="si">%s</span><span class="s1"> : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">------------- COPYING ATTRIBUTES ----------------------------</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">copy_attributes</span><span class="p">(</span><span class="n">h5_meas_group</span><span class="p">,</span> <span class="n">h5_some_dataset</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Attributes in {}:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">h5_some_dataset</span><span class="p">))</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_some_dataset</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="si">%s</span><span class="s1"> : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Attributes in &lt;HDF5 dataset &quot;Some_Dataset&quot;: shape (0, 1, 2, 3, 4), type &quot;&lt;f4&quot;&gt; before copying attributes:

------------- COPYING ATTRIBUTES ----------------------------

Attributes in &lt;HDF5 dataset &quot;Some_Dataset&quot;: shape (0, 1, 2, 3, 4), type &quot;&lt;f4&quot;&gt;:
        machine_id : challtdow-Aspire-F5-573G
        timestamp : 2018_07_31-13_16_15
        pyUSID_version : 0.0.4
        platform : Linux-4.15.0-29-generic-x86_64-with-debian-stretch-sid
        Instrument : Atomic Force Microscope
        User : Joe Smith
        Room Temperature [C] : 23
</pre></div>
</div>
<div class="section" id="writing-main-datasets">
<h3>Writing Main datasets<a class="headerlink" href="#writing-main-datasets" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="set-up-a-toy-problem">
<h2>Set up a toy problem<a class="headerlink" href="#set-up-a-toy-problem" title="Permalink to this headline">¶</a></h2>
<p>Let’s set up a toy four-dimensional dataset that has:</p>
<ul class="simple">
<li><dl class="first docutils">
<dt>two position dimensions:</dt>
<dd><ul class="first last">
<li>columns - X</li>
<li>rows - Y</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>and two spectroscopic dimensions:</dt>
<dd><ul class="first last">
<li>(sinusoidal) probing bias waveform</li>
<li>cycles over which this bias waveform is repeated</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>For simplicity, we will keep the size of each dimension small.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">num_rows</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_cycles</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">bias_pts</span> <span class="o">=</span> <span class="mi">7</span>
</pre></div>
</div>
</div>
<div class="section" id="specify-position-and-spectroscopic-dimensions">
<h2>Specify position and spectroscopic dimensions<a class="headerlink" href="#specify-position-and-spectroscopic-dimensions" title="Permalink to this headline">¶</a></h2>
<p>Next, let us determine how each of the position and spectroscopic dimensions are varied</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rows_vals</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">cols_vals</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">900</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">bias_vals</span> <span class="o">=</span> <span class="mf">2.5</span> <span class="o">*</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.sin.html#numpy.sin" title="View documentation for numpy.sin"><span class="n">np</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html#numpy.linspace" title="View documentation for numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><a href="https://docs.scipy.org/doc/numpy/reference/constants.html#numpy.pi" title="View documentation for numpy.pi"><span class="n">np</span><span class="o">.</span><span class="n">pi</span></a><span class="p">,</span> <span class="n">bias_pts</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">cycle_vals</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="n">num_cycles</span><span class="p">)</span>
</pre></div>
</div>
<p>For better understanding of this dataset, let us take a look at the different values these dimensions can take</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">vals</span><span class="p">,</span> <span class="n">dim_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">,</span> <span class="p">[</span><span class="n">rows_vals</span><span class="p">,</span> <span class="n">cols_vals</span><span class="p">,</span> <span class="n">bias_vals</span><span class="p">,</span> <span class="n">cycle_vals</span><span class="p">],</span>
                                <span class="p">[</span><span class="s1">&#39;Rows&#39;</span><span class="p">,</span> <span class="s1">&#39;Cols&#39;</span><span class="p">,</span> <span class="s1">&#39;Bias&#39;</span><span class="p">,</span> <span class="s1">&#39;Cycle&#39;</span><span class="p">]):</span>
    <span class="n">axis</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">dim_name</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">axis</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_hdf_utils_write_001.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_hdf_utils_write_001.png" />
<p>In the USID model, position and spectroscopic dimensions are defined using some basic information that will be
incorporated in <strong>Dimension</strong> objects that contain three vial pieces of information:</p>
<ul class="simple">
<li>Name of the dimension</li>
<li>units for the dimension</li>
<li><dl class="first docutils">
<dt>values:</dt>
<dd><ul class="first last">
<li>These can be the actual values over which the dimension was varied</li>
<li>or number of steps in case of linearly varying dimensions such as <code class="docutils literal notranslate"><span class="pre">Cycle</span></code> below</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Note that the Dimension objects in the lists for Positions and Spectroscopic must be arranged from fastest varying to
slowest varying to mimic how the data is actually arranged. For example, in this example, there are multiple
bias points per cycle and multiple columns per row of data. Thus, the <code class="docutils literal notranslate"><span class="pre">Bias</span></code> changes faster than the <code class="docutils literal notranslate"><span class="pre">Cycle</span></code> and
the columns change faster than the rows. Therefore, the  <code class="docutils literal notranslate"><span class="pre">Cols</span></code> must come before the <code class="docutils literal notranslate"><span class="pre">Rows</span></code> and <code class="docutils literal notranslate"><span class="pre">Bias</span></code> must precede
the <code class="docutils literal notranslate"><span class="pre">Cycle</span></code> dimension:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pos_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">usid</span><span class="o">.</span><span class="n">write_utils</span><span class="o">.</span><span class="n">Dimension</span><span class="p">(</span><span class="s1">&#39;Cols&#39;</span><span class="p">,</span> <span class="s1">&#39;nm&#39;</span><span class="p">,</span> <span class="n">cols_vals</span><span class="p">),</span>
            <span class="n">usid</span><span class="o">.</span><span class="n">write_utils</span><span class="o">.</span><span class="n">Dimension</span><span class="p">(</span><span class="s1">&#39;Rows&#39;</span><span class="p">,</span> <span class="s1">&#39;um&#39;</span><span class="p">,</span> <span class="n">rows_vals</span><span class="p">)]</span>
<span class="n">spec_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">usid</span><span class="o">.</span><span class="n">write_utils</span><span class="o">.</span><span class="n">Dimension</span><span class="p">(</span><span class="s1">&#39;Bias&#39;</span><span class="p">,</span> <span class="s1">&#39;V&#39;</span><span class="p">,</span> <span class="n">bias_vals</span><span class="p">),</span>
             <span class="n">usid</span><span class="o">.</span><span class="n">write_utils</span><span class="o">.</span><span class="n">Dimension</span><span class="p">(</span><span class="s1">&#39;Cycle&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">num_cycles</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="section" id="write-main-dataset">
<h2>write_main_dataset()<a class="headerlink" href="#write-main-dataset" title="Permalink to this headline">¶</a></h2>
<p>Often, data is is recorded (from instruments) or generated (as a result of some analysis) in chunks (for example - one
position at a time). Therefore, it makes sense to first create an empty dataset and then fill in the data as it is
generated / recorded.</p>
<p>We will only create an empty dataset first by specifying how large the dataset should be and of what data type
(specified using the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> keyword argument). Later, we will go over examples where the whole data is available when
creating the HDF5 dataset. The <code class="docutils literal notranslate"><span class="pre">write_main_dataset()</span></code> is <strong>one of the most important and popularly used functions</strong> in
<code class="docutils literal notranslate"><span class="pre">hdf_utils</span></code> since it handles:</p>
<ul class="simple">
<li>thorough validation of all inputs</li>
<li>the creation of the central dataset</li>
<li>the creation of the ancillary datasets (if necessary)</li>
<li>linking the ancillary datasets such that the central dataset becomes a <code class="docutils literal notranslate"><span class="pre">Main</span></code> dataset</li>
<li>writing attributes</li>
</ul>
<p>By default h5py does not appear to compress datasets and datasets (especially <code class="docutils literal notranslate"><span class="pre">Main</span></code> datasets) can balloon in size
if they are not compressed. Therefore, it is recommended that the compression keyword argument is passed as well.
<code class="docutils literal notranslate"><span class="pre">gzip</span></code> is the compression algorithm that is always available with h5py and it does a great job, so we will use this.</p>
<p>We could use the <code class="docutils literal notranslate"><span class="pre">write_simple_attrs()</span></code> function to write attributes to <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> at a later stage but we can always
pass these attributes to be written at the time of dataset creation if they are already known</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_raw</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_main_dataset</span><span class="p">(</span><span class="n">h5_meas_group</span><span class="p">,</span>  <span class="c1"># parent HDF5 group</span>
                                           <span class="p">(</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">bias_pts</span> <span class="o">*</span> <span class="n">num_cycles</span><span class="p">),</span>  <span class="c1"># shape of Main dataset</span>
                                           <span class="s1">&#39;Raw_Data&#39;</span><span class="p">,</span>  <span class="c1"># Name of main dataset</span>
                                           <span class="s1">&#39;Current&#39;</span><span class="p">,</span>  <span class="c1"># Physical quantity contained in Main dataset</span>
                                           <span class="s1">&#39;nA&#39;</span><span class="p">,</span>  <span class="c1"># Units for the physical quantity</span>
                                           <span class="n">pos_dims</span><span class="p">,</span>  <span class="c1"># Position dimensions</span>
                                           <span class="n">spec_dims</span><span class="p">,</span>  <span class="c1"># Spectroscopic dimensions</span>
                                           <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>  <span class="c1"># data type / precision</span>
                                           <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span>
                                           <span class="n">main_dset_attrs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;IO_rate&#39;</span><span class="p">:</span> <span class="mf">4E+6</span><span class="p">,</span> <span class="s1">&#39;Amplifier_Gain&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">})</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Raw_Data&quot;: shape (15, 14), type &quot;&lt;f4&quot;&gt;
located at:
        /Measurement_000/Raw_Data
Data contains:
        Current (nA)
Data dimensions and original shape:
Position Dimensions:
        Cols - size: 5
        Rows - size: 3
Spectroscopic Dimensions:
        Bias - size: 7
        Cycle - size: 2
Data Type:
        float32
</pre></div>
</div>
<p>Let us take a look at the contents of the file again using the <code class="docutils literal notranslate"><span class="pre">print_tree()</span></code> function. What we see is that five new
datasets have been created:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> was created to contain the 4D measurement we are interested in storing.</li>
<li><code class="docutils literal notranslate"><span class="pre">Spectroscopic_Indices</span></code> and Spectroscopic_Values`` contain the information about the spectroscopic dimensions</li>
<li><code class="docutils literal notranslate"><span class="pre">Position_Indices</span></code> and <code class="docutils literal notranslate"><span class="pre">Position_Values</span></code> contain the position related information</li>
</ul>
<p>The underline below <code class="docutils literal notranslate"><span class="pre">Measurement_000</span></code> indicates that this is a HDF5 Group</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/
├ Measurement_000
  ---------------
  ├ Position_Indices
  ├ Position_Values
  ├ Raw_Data
  ├ Spectroscopic_Indices
  ├ Spectroscopic_Values
├ Some_Group
  ----------
  ├ Some_Dataset
</pre></div>
</div>
<p>As mentioned in our <cite>document about the USID
model &lt;/../../../data_format.html&gt;</cite>, the four supporting datasets (<code class="docutils literal notranslate"><span class="pre">Indices</span></code> and
<code class="docutils literal notranslate"><span class="pre">Values</span></code> datasets for <code class="docutils literal notranslate"><span class="pre">Position</span></code> and <code class="docutils literal notranslate"><span class="pre">Spectroscopic</span></code>) help provide meaning to each element in <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> such as
dimensionality, etc.</p>
<p>Only <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> is a <code class="docutils literal notranslate"><span class="pre">USID</span> <span class="pre">Main</span> <span class="pre">dataset</span></code> while all other datasets are just supporting datasets. We can
verify whether a dataset is a Main dataset or not using the <code class="docutils literal notranslate"><span class="pre">check_if_main()</span></code> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="p">[</span><span class="n">h5_raw</span><span class="p">,</span> <span class="n">h5_raw</span><span class="o">.</span><span class="n">h5_spec_inds</span><span class="p">,</span> <span class="n">h5_raw</span><span class="o">.</span><span class="n">h5_pos_vals</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is {} is a Main dataset?: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">check_if_main</span><span class="p">(</span><span class="n">dset</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Is /Measurement_000/Raw_Data is a Main dataset?: True
Is /Measurement_000/Spectroscopic_Indices is a Main dataset?: False
Is /Measurement_000/Position_Values is a Main dataset?: False
</pre></div>
</div>
</div>
<div class="section" id="populating-the-dataset">
<h2>Populating the Dataset:<a class="headerlink" href="#populating-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>Note that h5_main still does not contain the values we are interested in filling it in with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
</pre></div>
</div>
<p>Let us simulate a situation where we are recording the data a pixel at a time and writing it to the h5_main dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">source_main_data</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html#numpy.random.rand" title="View documentation for numpy.random.rand"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">bias_pts</span> <span class="o">*</span> <span class="n">num_cycles</span><span class="p">)</span>

<span class="k">for</span> <span class="n">pixel_ind</span><span class="p">,</span> <span class="n">pixel_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">source_main_data</span><span class="p">):</span>
    <span class="n">h5_raw</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">pixel_data</span>

<span class="c1"># Make sure to ``flush`` the file (write anything in the buffer into the file)</span>
<span class="n">h5_file</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</pre></div>
</div>
<p>Note that we were only simulating a (realistic) situation where all the data was not present at once to write into
<code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> dataset. Let us check the contents at a particular position in the dataset now:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0.25428426 0.05224128 0.5453549  0.60507995 0.27090117 0.35579985
 0.5196121  0.7235666  0.8526963  0.56558836 0.4830766  0.252037
 0.52279985 0.37431818]
</pre></div>
</div>
</div>
<div class="section" id="exploring-attributes-in-main-datasets">
<h2>Exploring attributes in Main datasets:<a class="headerlink" href="#exploring-attributes-in-main-datasets" title="Permalink to this headline">¶</a></h2>
<p>Some of the main requirements for promoting a regular dataset to a Main dataset are some mandatory attributes attached
to the dataset:</p>
<ul class="simple">
<li>quantity - What the stored data contains - for example: current, temperature, voltage, strain etc.</li>
<li>units - the units for the quantity, such as Amperes, meters, etc.</li>
<li>links to each of the four ancillary datasets</li>
</ul>
<p>Again, we can use the <code class="docutils literal notranslate"><span class="pre">get_attributes()</span></code> function to see if and how these attributes are stored:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} : {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>quantity : Current
units : nA
IO_rate : 4000000.0
Amplifier_Gain : 9
machine_id : challtdow-Aspire-F5-573G
timestamp : 2018_07_31-13_16_15
pyUSID_version : 0.0.4
platform : Linux-4.15.0-29-generic-x86_64-with-debian-stretch-sid
Position_Indices : &lt;HDF5 object reference&gt;
Position_Values : &lt;HDF5 object reference&gt;
Spectroscopic_Indices : &lt;HDF5 object reference&gt;
Spectroscopic_Values : &lt;HDF5 object reference&gt;
</pre></div>
</div>
<p>While it is straightforward to read simple attributes like <code class="docutils literal notranslate"><span class="pre">quantity</span></code> or <code class="docutils literal notranslate"><span class="pre">units</span></code>, the values for <code class="docutils literal notranslate"><span class="pre">Position_Values</span></code> or
<code class="docutils literal notranslate"><span class="pre">Spectroscopic_Indices</span></code> attributes seem cryptic. These are just references or links to other datasets.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">,</span> <span class="s1">&#39;Position_Indices&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 object reference&gt;
</pre></div>
</div>
<div class="section" id="object-references-as-attributes">
<h3>Object references as attributes<a class="headerlink" href="#object-references-as-attributes" title="Permalink to this headline">¶</a></h3>
<p>We can get access to linked datasets using <code class="docutils literal notranslate"><span class="pre">get_auxiliary_datasets()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_auxiliary_datasets</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">,</span> <span class="s1">&#39;Position_Indices&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&lt;HDF5 dataset &quot;Position_Indices&quot;: shape (15, 2), type &quot;&lt;u4&quot;&gt;]
</pre></div>
</div>
<p>Given that <code class="docutils literal notranslate"><span class="pre">h5_raw</span></code> is a <code class="docutils literal notranslate"><span class="pre">Main</span></code> dataset, and`` Position_Indices`` is one of the four essential components of a <code class="docutils literal notranslate"><span class="pre">Main</span></code>
dataset, the <code class="docutils literal notranslate"><span class="pre">USIdataset</span></code> object makes it far easier to access the <code class="docutils literal notranslate"><span class="pre">ancillary</span> <span class="pre">datasets</span></code> without needing to call a
function as above.
<a class="reference external" href="./plot_usi_dataset.html">The USIDataset class</a>
has been discussed in greater detail in a separate document.</p>
<p>What do we do if we need to store some other supporting information regarding some measurement? If such supporting
datasets do not need to be <code class="docutils literal notranslate"><span class="pre">USID</span> <span class="pre">Main</span> <span class="pre">datasets</span></code>, we could simply use the basic functionality of <code class="docutils literal notranslate"><span class="pre">h5py</span></code> to create
the dataset</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_other</span> <span class="o">=</span> <span class="n">h5_meas_group</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;Other&#39;</span><span class="p">,</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html#numpy.random.rand" title="View documentation for numpy.random.rand"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
<p>h5USID files tend to have a fair number of datasets in them and the most important ones are <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">datasets</span></code> and
users tend to “walk” or “hop” through the file by stepping only on the <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">datasets</span></code>. Thus, we often want to link
supporting datasets to the relevant <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">datasets</span></code>. This way, such supporting datasets can be accessed via an
attribute of the <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code> instead of having to manually specify the path of the supporting dataset.</p>
</div>
</div>
<div class="section" id="link-h5-objects-as-attrs">
<h2>link_h5_objects_as_attrs()<a class="headerlink" href="#link-h5-objects-as-attrs" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">link_h5_objects_as_attrs()</span></code> makes it easy to link a dataset or group to any other dataset or group. In this example
we will link the <code class="docutils literal notranslate"><span class="pre">Other</span></code> dataset to the <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">link_h5_objects_as_attrs</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">,</span> <span class="n">h5_other</span><span class="p">)</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} : {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>quantity : Current
units : nA
IO_rate : 4000000.0
Amplifier_Gain : 9
machine_id : challtdow-Aspire-F5-573G
timestamp : 2018_07_31-13_16_15
pyUSID_version : 0.0.4
platform : Linux-4.15.0-29-generic-x86_64-with-debian-stretch-sid
Position_Indices : &lt;HDF5 object reference&gt;
Position_Values : &lt;HDF5 object reference&gt;
Spectroscopic_Indices : &lt;HDF5 object reference&gt;
Spectroscopic_Values : &lt;HDF5 object reference&gt;
Other : &lt;HDF5 object reference&gt;
</pre></div>
</div>
<p>In the same way, we can even link a group to the <code class="docutils literal notranslate"><span class="pre">Other</span></code> dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">link_h5_objects_as_attrs</span><span class="p">(</span><span class="n">h5_other</span><span class="p">,</span> <span class="n">h5_some_group</span><span class="p">)</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_other</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} : {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Some_Group : &lt;HDF5 object reference&gt;
</pre></div>
</div>
<p>What we see above is that ‘Other’ is now an attribute of the ‘Raw_Data’ dataset.</p>
<p>One common scenario in scientific workflows is the storage of multiple <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">Datasets</span></code> within the same group. The
first <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code> can be stored along with its four <code class="docutils literal notranslate"><span class="pre">ancillary</span> <span class="pre">datasets</span></code> without any problems. However, if the
second <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code> also requires the storage of <code class="docutils literal notranslate"><span class="pre">Position</span></code> and <code class="docutils literal notranslate"><span class="pre">Spectroscopic</span></code> datasets, these datasets would need
to be named differently to avoid conflicts with existing datasets (associated with the first <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code>). Moreover
, these <code class="docutils literal notranslate"><span class="pre">ancillary</span> <span class="pre">datasets</span></code> would need to be linked to the second <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code> with the standard <code class="docutils literal notranslate"><span class="pre">Position_..</span></code> and
<code class="docutils literal notranslate"><span class="pre">Spectroscopic_..</span></code> names for the attributes.</p>
</div>
<div class="section" id="link-h5-obj-as-alias">
<h2>link_h5_obj_as_alias()<a class="headerlink" href="#link-h5-obj-as-alias" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">link_h5_obj_as_alias()</span></code> is handy in this scenario since it allows a dataset or group to be linked with a name
different from its actual name. For example, we can link the <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> dataset to the <code class="docutils literal notranslate"><span class="pre">Other</span></code> dataset with an alias:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">link_h5_obj_as_alias</span><span class="p">(</span><span class="n">h5_other</span><span class="p">,</span> <span class="n">h5_raw</span><span class="p">,</span> <span class="s1">&#39;Mysterious_Dataset&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_attributes</span><span class="p">(</span><span class="n">h5_other</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} : {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Some_Group : &lt;HDF5 object reference&gt;
Mysterious_Dataset : &lt;HDF5 object reference&gt;
</pre></div>
</div>
<p>The dataset named <code class="docutils literal notranslate"><span class="pre">Other</span></code> has a new attribute named <code class="docutils literal notranslate"><span class="pre">Mysterious_Dataset</span></code>. Let us show that this dataset is none other
than <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_myst_dset</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_auxiliary_datasets</span><span class="p">(</span><span class="n">h5_other</span><span class="p">,</span> <span class="s1">&#39;Mysterious_Dataset&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_myst_dset</span> <span class="o">==</span> <span class="n">h5_raw</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
<div class="section" id="processing-on-datasets">
<h3>Processing on Datasets<a class="headerlink" href="#processing-on-datasets" title="Permalink to this headline">¶</a></h3>
<p>Lets assume that we are normalizing the data in some way and we need to write the results back to the file. As far
as the data shapes and dimensionality are concerned, let us assume that the data still remains a 4D dataset.</p>
</div>
</div>
<div class="section" id="create-results-group">
<h2>create_results_group()<a class="headerlink" href="#create-results-group" title="Permalink to this headline">¶</a></h2>
<p>Let us first start off with creation of a HDF5 Group that will contain the results. If you recall, groups that contain
the results of some processing / analysis on a source dataset are named as <code class="docutils literal notranslate"><span class="pre">Source_Dataset_name-Process_Name_00x</span></code>
where the index of the group. The <code class="docutils literal notranslate"><span class="pre">create_results_group()</span></code> function makes it very easy to create a group with such
nomenclature and indexing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_results_group_1</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">create_results_group</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">,</span> <span class="s1">&#39;Normalization&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_results_group_1</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 group &quot;/Measurement_000/Raw_Data-Normalization_000&quot; (0 members)&gt;
</pre></div>
</div>
<p>Let us make up some (random) data which is the result of some Normalization on the <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">norm_data</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html#numpy.random.rand" title="View documentation for numpy.random.rand"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">bias_pts</span> <span class="o">*</span> <span class="n">num_cycles</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="writing-the-main-dataset">
<h2>Writing the main dataset<a class="headerlink" href="#writing-the-main-dataset" title="Permalink to this headline">¶</a></h2>
<p>In this scenario we will demonstrate how one might write a <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code> when having the complete processed (in this
case some normalization) data is available before even creating the dataset.</p>
<p>One more important point to remember here is that the normalized data is of the same shape and dimensionality as
<code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code>. Therefore, we need not unnecessarily create ancillary datasets - we can simply refer to the ones that
support <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code>. During the creation of <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code>, we passed the <code class="docutils literal notranslate"><span class="pre">pos_dims</span></code> and <code class="docutils literal notranslate"><span class="pre">spec_dims</span></code> parameters for the
creation of new <code class="docutils literal notranslate"><span class="pre">Ancillary</span> <span class="pre">datasets</span></code>. In this case, we will show how we can ask <code class="docutils literal notranslate"><span class="pre">write_main_dataset()</span></code> to reuse
existing ancillary datasets:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_norm</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_main_dataset</span><span class="p">(</span><span class="n">h5_results_group_1</span><span class="p">,</span>  <span class="c1"># parent group</span>
                                            <span class="n">norm_data</span><span class="p">,</span>  <span class="c1"># data to be written</span>
                                            <span class="s1">&#39;Normalized_Data&#39;</span><span class="p">,</span>  <span class="c1"># Name of the main dataset</span>
                                            <span class="s1">&#39;Current&#39;</span><span class="p">,</span>  <span class="c1"># quantity</span>
                                            <span class="s1">&#39;nA&#39;</span><span class="p">,</span>  <span class="c1"># units</span>
                                            <span class="bp">None</span><span class="p">,</span>  <span class="c1"># position dimensions</span>
                                            <span class="bp">None</span><span class="p">,</span>  <span class="c1"># spectroscopic dimensions</span>
                                            <span class="n">h5_pos_inds</span><span class="o">=</span><span class="n">h5_raw</span><span class="o">.</span><span class="n">h5_pos_inds</span><span class="p">,</span>
                                            <span class="n">h5_pos_vals</span><span class="o">=</span><span class="n">h5_raw</span><span class="o">.</span><span class="n">h5_pos_vals</span><span class="p">,</span>
                                            <span class="n">h5_spec_inds</span><span class="o">=</span><span class="n">h5_raw</span><span class="o">.</span><span class="n">h5_spec_inds</span><span class="p">,</span>
                                            <span class="n">h5_spec_vals</span><span class="o">=</span><span class="n">h5_raw</span><span class="o">.</span><span class="n">h5_spec_vals</span><span class="p">,</span>
                                            <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_norm</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Normalized_Data&quot;: shape (15, 14), type &quot;&lt;f8&quot;&gt;
located at:
        /Measurement_000/Raw_Data-Normalization_000/Normalized_Data
Data contains:
        Current (nA)
Data dimensions and original shape:
Position Dimensions:
        Cols - size: 5
        Rows - size: 3
Spectroscopic Dimensions:
        Bias - size: 7
        Cycle - size: 2
Data Type:
        float64
</pre></div>
</div>
<p>When we look at the contents of hte file again, what we see below is that the newly created group
<code class="docutils literal notranslate"><span class="pre">Raw_Data-Normalization_000</span></code> only contains the <code class="docutils literal notranslate"><span class="pre">Normalized_Data</span></code> dataset and none of the supporting ancillary datasets
since it is sharing the same ones created for <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/
├ Measurement_000
  ---------------
  ├ Other
  ├ Position_Indices
  ├ Position_Values
  ├ Raw_Data
  ├ Raw_Data-Normalization_000
    --------------------------
    ├ Normalized_Data
  ├ Spectroscopic_Indices
  ├ Spectroscopic_Values
├ Some_Group
  ----------
  ├ Some_Dataset
</pre></div>
</div>
</div>
<div class="section" id="shared-ancillary-datasets">
<h2>Shared ancillary datasets<a class="headerlink" href="#shared-ancillary-datasets" title="Permalink to this headline">¶</a></h2>
<p>Let us verify that <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> and <code class="docutils literal notranslate"><span class="pre">Normalized_Data</span></code> share the same ancillary datasets:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">anc_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Position_Indices&#39;</span><span class="p">,</span> <span class="s1">&#39;Position_Values&#39;</span><span class="p">,</span> <span class="s1">&#39;Spectroscopic_Indices&#39;</span><span class="p">,</span> <span class="s1">&#39;Spectroscopic_Values&#39;</span><span class="p">]:</span>
    <span class="c1"># get the handle to the ancillary dataset linked to &#39;Raw_Data&#39;</span>
    <span class="n">raw_anc</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_auxiliary_datasets</span><span class="p">(</span><span class="n">h5_raw</span><span class="p">,</span> <span class="n">anc_name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># get the handle to the ancillary dataset linked to &#39;Normalized_Data&#39;</span>
    <span class="n">norm_anc</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">get_auxiliary_datasets</span><span class="p">(</span><span class="n">h5_norm</span><span class="p">,</span> <span class="n">anc_name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Show that these are indeed the same dataset</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Sharing {}: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">anc_name</span><span class="p">,</span> <span class="n">raw_anc</span> <span class="o">==</span> <span class="n">norm_anc</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Sharing Position_Indices: True
Sharing Position_Values: True
Sharing Spectroscopic_Indices: True
Sharing Spectroscopic_Values: True
</pre></div>
</div>
<p>Unlike last time with <code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code>, we wrote the data to the file when creating <code class="docutils literal notranslate"><span class="pre">Normalized_Data</span></code>, so let us check to
make sure that we did in fact write data to disk:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">h5_norm</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0.19123188 0.06292482 0.90990684 0.24585696 0.78756491 0.79926715
 0.87184476 0.36021846 0.66203173 0.0718334  0.81087041 0.33533243
 0.68340938 0.60059189]
</pre></div>
</div>
<div class="section" id="duplicating-datasets">
<h3>Duplicating Datasets<a class="headerlink" href="#duplicating-datasets" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="create-empty-dataset">
<h2>create_empty_dataset()<a class="headerlink" href="#create-empty-dataset" title="Permalink to this headline">¶</a></h2>
<p>Let us say that we are interested in writing out another dataset that is again of the same shape and dimensionality as
<code class="docutils literal notranslate"><span class="pre">Raw_Data</span></code> or <code class="docutils literal notranslate"><span class="pre">Normalized_Data</span></code>. There is another way to create an empty dataset identical to an existing dataset,
and then fill it in. This approach is an alternative to the approach used for <code class="docutils literal notranslate"><span class="pre">Normalized_Data</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_offsets</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">create_empty_dataset</span><span class="p">(</span><span class="n">h5_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">&#39;Offsets&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_offsets</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Offsets&quot;: shape (15, 14), type &quot;&lt;f4&quot;&gt;
located at:
        /Measurement_000/Raw_Data-Normalization_000/Offsets
Data contains:
        Current (nA)
Data dimensions and original shape:
Position Dimensions:
        Cols - size: 5
        Rows - size: 3
Spectroscopic Dimensions:
        Bias - size: 7
        Cycle - size: 2
Data Type:
        float32
</pre></div>
</div>
<p>In this very specific scenario, we duplicated practically all aspects of <code class="docutils literal notranslate"><span class="pre">Normalized_Data</span></code>, including its links to the
ancillary datasets. Thus, this <code class="docutils literal notranslate"><span class="pre">h5_offsets</span></code> automatically also becomes a <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code>.</p>
<p>However, it is empty and needs to be populated</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">h5_offsets</span><span class="p">[</span><span class="mi">6</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
</pre></div>
</div>
<p>Since this is an example, we will populate the dataset using same data prepare for <code class="docutils literal notranslate"><span class="pre">norm_data</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_offsets</span><span class="p">[()]</span> <span class="o">=</span> <span class="n">norm_data</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_offsets</span><span class="p">[</span><span class="mi">6</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0.22788014 0.8602242  0.9181152  0.27735272 0.65445894 0.535692
 0.06081086 0.5786002  0.3128312  0.80562574 0.6513641  0.6491842
 0.30136934 0.32722104]
</pre></div>
</div>
<div class="section" id="creating-ancillary-datasets">
<h3>Creating Ancillary datasets<a class="headerlink" href="#creating-ancillary-datasets" title="Permalink to this headline">¶</a></h3>
<p>Often, certain processing of data involves the removal of one or more dimensions (typically <code class="docutils literal notranslate"><span class="pre">Spectroscopic</span></code>). This
necessitates careful generation of <code class="docutils literal notranslate"><span class="pre">indices</span></code> and <code class="docutils literal notranslate"><span class="pre">values</span></code> datasets. In our example, we will remove the spectroscopic
dimension - <code class="docutils literal notranslate"><span class="pre">Bias</span></code> and leave the position dimensions as is. While we could simply regenerate the spectroscopic indices
from scratch knowing that the only remaining spectroscopic dimension is <code class="docutils literal notranslate"><span class="pre">Cycle</span></code>, this is not feasible when writing
robust code where we have minimal control or knowledge about the other dimensions. This is especially true when there
are 3 or more spectroscopic dimensions and we do not know relationships between the spectroscopic dimensions or the
rates of change in these spectroscopic dimensions. Fortunately, <code class="docutils literal notranslate"><span class="pre">hdf_utils.write_reduced_spec_dsets()</span></code> substantially
simplifies this problem as shown below.</p>
<p>First, we still need to create the results HDF5 group to hold the results:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_analysis_group</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">create_results_group</span><span class="p">(</span><span class="n">h5_norm</span><span class="p">,</span> <span class="s1">&#39;Fitting&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Let us take a look at the contents of the HDF5 file again. Clearly, we do not have any new datasets underneath
<code class="docutils literal notranslate"><span class="pre">Normalized_Data-Fitting_000</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/
├ Measurement_000
  ---------------
  ├ Other
  ├ Position_Indices
  ├ Position_Values
  ├ Raw_Data
  ├ Raw_Data-Normalization_000
    --------------------------
    ├ Normalized_Data
    ├ Normalized_Data-Fitting_000
      ---------------------------
    ├ Offsets
  ├ Spectroscopic_Indices
  ├ Spectroscopic_Values
├ Some_Group
  ----------
  ├ Some_Dataset
</pre></div>
</div>
</div>
</div>
<div class="section" id="write-reduced-spec-dsets">
<h2>write_reduced_spec_dsets()<a class="headerlink" href="#write-reduced-spec-dsets" title="Permalink to this headline">¶</a></h2>
<p>Now we make the new spectroscopic indices and values datasets while removing the <code class="docutils literal notranslate"><span class="pre">Bias</span></code> dimension</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_spec_inds</span><span class="p">,</span> <span class="n">h5_spec_vals</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_reduced_spec_dsets</span><span class="p">(</span><span class="n">h5_analysis_group</span><span class="p">,</span>
                                                                   <span class="n">h5_norm</span><span class="o">.</span><span class="n">h5_spec_inds</span><span class="p">,</span>
                                                                   <span class="n">h5_norm</span><span class="o">.</span><span class="n">h5_spec_vals</span><span class="p">,</span>
                                                                   <span class="s1">&#39;Bias&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_spec_inds</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Spectroscopic_Indices&quot;: shape (1, 2), type &quot;&lt;u4&quot;&gt;
</pre></div>
</div>
<p>Let us take a look at the contents only inside h5_analysis_group now. Clearly, we have created two new spectroscopic
ancillary datasets.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_analysis_group</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/Measurement_000/Raw_Data-Normalization_000/Normalized_Data-Fitting_000
├ Spectroscopic_Indices
├ Spectroscopic_Values
</pre></div>
</div>
</div>
<div class="section" id="write-ind-val-dsets">
<h2>write_ind_val_dsets()<a class="headerlink" href="#write-ind-val-dsets" title="Permalink to this headline">¶</a></h2>
<p>Similar to <code class="docutils literal notranslate"><span class="pre">write_reduced_spec_dsets()</span></code>, <code class="docutils literal notranslate"><span class="pre">hdf_utils</span></code> also has another function called <code class="docutils literal notranslate"><span class="pre">write_ind_val_dsets()</span></code> that is
handy when one needs to create the ancillary datasets before <code class="docutils literal notranslate"><span class="pre">write_main_dataset()</span></code> is called. For example, consider a
data processing algorithm that may or may not change the position dimensions. You may need to structure your code this
way:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">position</span> <span class="n">dimensions</span> <span class="n">are</span> <span class="n">unchanged</span><span class="p">:</span>
  <span class="c1"># get links to datasets from the source dataset</span>
  <span class="n">h5_pos_inds</span><span class="p">,</span> <span class="n">h5_pos_vals</span> <span class="o">=</span> <span class="n">h5_source</span><span class="o">.</span><span class="n">h5_pos_inds</span><span class="p">,</span> <span class="n">h5_source</span><span class="o">.</span><span class="n">h5_pos_vals</span>
<span class="k">else</span><span class="p">:</span>
  <span class="c1"># Need to create fresh HDF5 datasets</span>
  <span class="n">h5_pos_inds</span><span class="p">,</span> <span class="n">h5_pos_vals</span> <span class="o">=</span> <span class="n">write_ind_val_dsets</span><span class="p">()</span>

<span class="c1"># At this point, it does not matter how we got h5_pos_inds, h5_pos_vals. We can simply link them when we</span>
<span class="c1"># create the main dataset.</span>
<span class="n">h5_new_main</span> <span class="o">=</span> <span class="n">write_main_dataset</span><span class="p">(</span><span class="o">....</span><span class="p">,</span> <span class="n">h5_pos_inds</span><span class="o">=</span><span class="n">h5_pos_inds</span><span class="p">,</span> <span class="n">h5_pos_vals</span><span class="o">=</span><span class="n">h5_pos_vals</span><span class="p">)</span>
</pre></div>
</div>
<p>Even though we already decided that we would not be changing the position dimensions for this particular example, we
will demonstrate the usage of <code class="docutils literal notranslate"><span class="pre">write_ind_val_dsets()</span></code> to make <code class="docutils literal notranslate"><span class="pre">position</span> <span class="pre">indices</span></code> and <code class="docutils literal notranslate"><span class="pre">values</span></code> HDF5 datasets (that are
identical to the ones already linked to <code class="docutils literal notranslate"><span class="pre">h5_norm</span></code>)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_pos_inds</span><span class="p">,</span> <span class="n">h5_pos_vals</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_ind_val_dsets</span><span class="p">(</span><span class="n">h5_analysis_group</span><span class="p">,</span> <span class="n">pos_dims</span><span class="p">,</span> <span class="n">is_spectral</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Looking at the contents of <code class="docutils literal notranslate"><span class="pre">Normalized_Data-Fitting_000</span></code> now reveals that we have added the <code class="docutils literal notranslate"><span class="pre">Position</span></code> datasets as
well. However, we still do not have the <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_analysis_group</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/Measurement_000/Raw_Data-Normalization_000/Normalized_Data-Fitting_000
├ Position_Indices
├ Position_Values
├ Spectroscopic_Indices
├ Spectroscopic_Values
</pre></div>
</div>
<p>Finally, we can create and write a Main dataset with some results using the trusty write_main_dataset function. Since
we have created both the Spectroscopic and Position HDF5 dataset pairs, we simply ask write_main_dataset() to re-use
+ link them. This is why the <code class="docutils literal notranslate"><span class="pre">pos_dims</span></code> and <code class="docutils literal notranslate"><span class="pre">spec_dims</span></code> arguments are None (we don’t want to create new datasets).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reduced_main</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html#numpy.random.rand" title="View documentation for numpy.random.rand"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">num_cycles</span><span class="p">)</span>
<span class="n">h5_cap_1</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_main_dataset</span><span class="p">(</span><span class="n">h5_analysis_group</span><span class="p">,</span>  <span class="c1"># parent HDF5 group</span>
                                           <span class="n">reduced_main</span><span class="p">,</span>  <span class="c1"># data for Main dataset</span>
                                           <span class="s1">&#39;Capacitance&#39;</span><span class="p">,</span>  <span class="c1"># Name of Main dataset</span>
                                           <span class="s1">&#39;Capacitance&#39;</span><span class="p">,</span>  <span class="c1"># Quantity</span>
                                           <span class="s1">&#39;pF&#39;</span><span class="p">,</span>  <span class="c1"># units</span>
                                           <span class="bp">None</span><span class="p">,</span>  <span class="c1"># position dimensions</span>
                                           <span class="bp">None</span><span class="p">,</span>  <span class="c1"># spectroscopic dimensions</span>
                                           <span class="n">h5_spec_inds</span><span class="o">=</span><span class="n">h5_spec_inds</span><span class="p">,</span>
                                           <span class="n">h5_spec_vals</span><span class="o">=</span><span class="n">h5_spec_vals</span><span class="p">,</span>
                                           <span class="n">h5_pos_inds</span><span class="o">=</span><span class="n">h5_pos_inds</span><span class="p">,</span>
                                           <span class="n">h5_pos_vals</span><span class="o">=</span><span class="n">h5_pos_vals</span><span class="p">,</span>
                                             <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_cap_1</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Capacitance&quot;: shape (15, 2), type &quot;&lt;f8&quot;&gt;
located at:
        /Measurement_000/Raw_Data-Normalization_000/Normalized_Data-Fitting_000/Capacitance
Data contains:
        Capacitance (pF)
Data dimensions and original shape:
Position Dimensions:
        Cols - size: 5
        Rows - size: 3
Spectroscopic Dimensions:
        Cycle - size: 2
Data Type:
        float64
</pre></div>
</div>
<div class="section" id="multiple-main-datasets">
<h3>Multiple Main Datasets<a class="headerlink" href="#multiple-main-datasets" title="Permalink to this headline">¶</a></h3>
<p>Let’s say that we need to create a new <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code> within the same folder as <code class="docutils literal notranslate"><span class="pre">Capacitance</span></code> called
<code class="docutils literal notranslate"><span class="pre">Mean_Capacitance</span></code>. <code class="docutils literal notranslate"><span class="pre">Mean_Capacitance</span></code> would just be a spatial map with average capacitance, so it would not even have
the <code class="docutils literal notranslate"><span class="pre">Cycle</span></code> spectroscopic dimension. This means that we can reuse the newly created <code class="docutils literal notranslate"><span class="pre">Position</span> <span class="pre">ancillary</span> <span class="pre">datasets</span></code> but
we would need to create new <code class="docutils literal notranslate"><span class="pre">Spectroscopic_Indices</span></code> and <code class="docutils literal notranslate"><span class="pre">Spectroscopic_Values</span></code> datasets in the same folder to express
the 0 dimensions in the spectroscopic axis for this new dataset. However, we already have datasets of this name that
we created above using the <code class="docutils literal notranslate"><span class="pre">write_reduced_spec_dsets()</span></code> function. Recall, that the criterion for a <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">dataset</span></code> is
that it should have attributes of name <code class="docutils literal notranslate"><span class="pre">Spectroscopic_Indices</span></code> and <code class="docutils literal notranslate"><span class="pre">Spectroscopic_Values</span></code>. <strong>It does not matter what
the actual name of the linked datasets are</strong>. Coming back to the current example, we could simply ask
<code class="docutils literal notranslate"><span class="pre">write_main_dataset()</span></code> to name the spectroscopic datasets with a different prefix - <code class="docutils literal notranslate"><span class="pre">Empty_Spec</span></code> instead of
<code class="docutils literal notranslate"><span class="pre">Spectroscopic</span></code> (which is the default) via the <code class="docutils literal notranslate"><span class="pre">aux_spec_prefix</span></code> keyword argument (last line). This allows the
creation of the new Main Dataset without any name clashes with existing datasets:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_cap_2</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_main_dataset</span><span class="p">(</span><span class="n">h5_analysis_group</span><span class="p">,</span>  <span class="c1"># Parent HDF5 group</span>
                                           <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html#numpy.random.rand" title="View documentation for numpy.random.rand"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># Main Data</span>
                                           <span class="s1">&#39;Mean_Capacitance&#39;</span><span class="p">,</span>  <span class="c1"># Name of Main Dataset</span>
                                           <span class="s1">&#39;Capacitance&#39;</span><span class="p">,</span>  <span class="c1"># Physical quantity</span>
                                           <span class="s1">&#39;pF&#39;</span><span class="p">,</span>  <span class="c1"># Units</span>
                                           <span class="bp">None</span><span class="p">,</span>  <span class="c1"># Position dimensions</span>
                                           <span class="n">usid</span><span class="o">.</span><span class="n">write_utils</span><span class="o">.</span><span class="n">Dimension</span><span class="p">(</span><span class="s1">&#39;Capacitance&#39;</span><span class="p">,</span> <span class="s1">&#39;pF&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># Spectroscopic dimensions</span>
                                           <span class="n">h5_pos_inds</span><span class="o">=</span><span class="n">h5_pos_inds</span><span class="p">,</span>
                                           <span class="n">h5_pos_vals</span><span class="o">=</span><span class="n">h5_pos_vals</span><span class="p">,</span>
                                           <span class="n">aux_spec_prefix</span><span class="o">=</span><span class="s1">&#39;Empty_Spec&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_cap_2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Mean_Capacitance&quot;: shape (15, 1), type &quot;&lt;f8&quot;&gt;
located at:
        /Measurement_000/Raw_Data-Normalization_000/Normalized_Data-Fitting_000/Mean_Capacitance
Data contains:
        Capacitance (pF)
Data dimensions and original shape:
Position Dimensions:
        Cols - size: 5
        Rows - size: 3
Spectroscopic Dimensions:
        Capacitance - size: 1
Data Type:
        float64
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">compression</span></code> argument need not be specified for small datasets such as <code class="docutils literal notranslate"><span class="pre">Mean</span> <span class="pre">Capacitance</span></code>.
Clearly, <code class="docutils literal notranslate"><span class="pre">Mean_Capacitance</span></code> and <code class="docutils literal notranslate"><span class="pre">Capacitance</span></code> are two <code class="docutils literal notranslate"><span class="pre">Main</span> <span class="pre">datasets</span></code> that coexist in the same HDF5 group along
with their necessary ancillary datasets.</p>
<p>Now, let us look at the contents of the group: <code class="docutils literal notranslate"><span class="pre">Normalized_Data-Fitting_000</span></code> to verify this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_analysis_group</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/Measurement_000/Raw_Data-Normalization_000/Normalized_Data-Fitting_000
├ Capacitance
├ Empty_Spec_Indices
├ Empty_Spec_Values
├ Mean_Capacitance
├ Position_Indices
├ Position_Values
├ Spectroscopic_Indices
├ Spectroscopic_Values
</pre></div>
</div>
</div>
<div class="section" id="file-status">
<h3>File status<a class="headerlink" href="#file-status" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="is-editable-h5">
<h2>is_editable_h5()<a class="headerlink" href="#is-editable-h5" title="Permalink to this headline">¶</a></h2>
<p>When writing a class or a function that modifies or adds data to an existing HDF5 file, it is a good idea to check to
make sure that it is indeed possible to write the new data to the file. <code class="docutils literal notranslate"><span class="pre">is_editable_h5()</span></code> is a handy function for
this very purpose:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is the file editable?: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">is_editable_h5</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Is the file editable?: True
</pre></div>
</div>
<p>If we close the file and try again we should expect runtime and Value errors. You can try this by yourself if you like</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="c1"># print(&#39;Is the file editable?: {}&#39;.format(usid.hdf_utils.is_editable_h5(h5_file)))</span>
</pre></div>
</div>
<p>Let us try again by opening this file in read-only mode. We should see that the file will not be editable:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="s1">&#39;test.h5&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is the file editable?: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">is_editable_h5</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Is the file editable?: False
</pre></div>
</div>
<p>Closing and deleting the file</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 0 minutes  0.168 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-cookbooks-plot-hdf-utils-write-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_hdf_utils_write.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_hdf_utils_write.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_hdf_utils_write.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_hdf_utils_write.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="plot_process.html" class="btn btn-neutral float-right" title="10. Formalizing Data Processing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="plot_write_utils.html" class="btn btn-neutral" title="08. Utilities that assist in writing USID data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Suhas Somnath, Chris R. Smith, Stephen Jesse.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.0.4',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>