

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>10. Formalizing Data Processing &mdash; pyUSID 0.0.4 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11. Input / Output / Computing utilities" href="plot_io_utils.html" />
    <link rel="prev" title="09. Utilities for writing h5USID files" href="plot_hdf_utils_write.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> pyUSID
          

          
          </a>

          
            
            
              <div class="version">
                0.0.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about.html">pyUSID</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../external_guides.html">Tutorials on Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package_organization.html">Package Organization</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples &amp; Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#guides-to-pyusid">Guides to pyUSID</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_h5py.html">01. Primer to HDF5 and h5py</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_usi_dataset.html">02. The USIDataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_numpy_translator.html">03. Translation and the NumpyTranslator</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_plot_utils.html">04. Plotting utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_hdf_utils_read.html">05. Utilities for reading h5USID files</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_dtype_utils.html">06. Utilities for handling data types and transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_parallel_compute.html">07. Speed up computations with parallel_compute()</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_write_utils.html">08. Utilities that assist in writing USID data</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_hdf_utils_write.html">09. Utilities for writing h5USID files</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">10. Formalizing Data Processing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#components-of-pyusid-process">Components of pyUSID.Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="#recommended-pre-requisite-reading">Recommended pre-requisite reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-problem">Example problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-necessary-packages">Import necessary packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="#map-function">map_function()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#test">test()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-results-datasets">create_results_datasets()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write-results-chunk">write_results_chunk()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#comments">Comments</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-the-dataset">Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#instantiation">Instantiation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">test()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compute">compute()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#visualize">Visualize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#clean-up">Clean up</a></li>
<li class="toctree-l4"><a class="reference internal" href="#init">init()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">test()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">compute()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#use-partial-computation">use_partial_computation()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#advanced-examples">Advanced examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="#juggling-dimensions">Juggling dimensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#computing-on-chunks-instead-of-mapping">Computing on chunks instead of mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="#other-notes">Other Notes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_io_utils.html">11. Input / Output / Computing utilities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../data_format.html">Data Model and File Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribution_guidelines.html">Guidelines for Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../credits.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../whats_new.html">What’s New</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../matlab_to_python.html">Upgrading from Matlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pyUSID</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Examples &amp; Tutorials</a> &raquo;</li>
        
      <li>10. Formalizing Data Processing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/auto_examples/cookbooks/plot_process.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-auto-examples-cookbooks-plot-process-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="formalizing-data-processing">
<span id="sphx-glr-auto-examples-cookbooks-plot-process-py"></span><h1>10. Formalizing Data Processing<a class="headerlink" href="#formalizing-data-processing" title="Permalink to this headline">¶</a></h1>
<p><strong>Suhas Somnath</strong></p>
<p>4/26/2018</p>
<p><strong>In this example, we will learn how to write a simple yet formal pyUSID class for processing data.</strong></p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Most of code written for scientific research is in the form of single-use / one-off scripts due to a few common
reasons:</p>
<ul class="simple">
<li>the author feels that it is the fastest mode to accomplishing a research task</li>
<li>the author feels that they are unlikely to perform the same operation again</li>
<li>the author does not anticipate the possibility that others may need to run their code</li>
</ul>
<p>However, more often than not, nearly all researchers have found that one or more of these assumptions fail and a lot
of time is spent on fixing bugs and generalizing / formalizing code such that it can be shared or reused. Moreover, we
live in an era of open science where the scientific community and an ever-increasing number of scientific journals
are moving towards a paradigm where the data and code need to be made available with journal papers. Therefore, in the
interest of saving time, energy, and reputation (you do not want to show ugly code / data. Instead you want to be the
paragon of clean intelligible data and code), it makes a lot more sense to formalize (parts of) one’s data analysis
code.</p>
<p>For many researchers, formalizing data processing or analysis may seem like a daunting task due to the complexity of
and the number of sub-operations that need to performed. <code class="docutils literal notranslate"><span class="pre">pyUSID.Process</span></code> greatly simplifies the process of
formalizing code by lifting or reducing the burden of implementing important, yet tedious tasks and considerations
such as:</p>
<ul class="simple">
<li><strong>memory management</strong> - reading chunks of datasets that can be processed with the available memory, something very
crucial for very large datasets that cannot entirely fit into the computer’s memory</li>
<li><strong>considerate CPU usage for parallel computing</strong> - using all but one or two CPU cores for the (parallel) computation
, which allows the user to continue using the computer for other activities such as reading mail, etc.</li>
<li><strong>pausing and resuming computation</strong> - interrupting and resuming the computation at a more convenient time,
something that is especially valuable for lengthy computations.</li>
<li><strong>avoiding repeated computation and returning existing results</strong> - pyUSID.Process will return existing results
computed using the exact same parameters instead of re-computing and storing duplicate copies of the same results.</li>
<li><strong>testing before computation</strong> - checking the processing / analysis on a single unit (typically a single pixel) of
data before the entire data is processed. This is particularly useful for lengthy computations.</li>
</ul>
<p>Using <code class="docutils literal notranslate"><span class="pre">pyUSID.Process</span></code>, the user only needs to address the following basic operations:</p>
<ol class="arabic simple">
<li>Reading data from file</li>
<li>Computation on a single unit of data</li>
<li>Writing results to disk</li>
</ol>
</div>
<div class="section" id="components-of-pyusid-process">
<h2>Components of pyUSID.Process<a class="headerlink" href="#components-of-pyusid-process" title="Permalink to this headline">¶</a></h2>
<p>The most important functions in the Process class are:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">__init__()</span></code> - instantiates a ‘Process’ object of this class after validating the inputs.</li>
<li><code class="docutils literal notranslate"><span class="pre">_create_results_datasets()</span></code> - creates the HDF5 datasets and Group(s) to store the results.</li>
<li><code class="docutils literal notranslate"><span class="pre">_map_function()</span></code> - the operation that will per be performed on each element in the dataset.</li>
<li><code class="docutils literal notranslate"><span class="pre">test()</span></code> - This simple function lets the user test the <code class="docutils literal notranslate"><span class="pre">map_function</span></code> on a unit of data (a single pixel
typically) to see if it returns the desired results. It saves a lot of computational time by allowing the user to
spot-check results before computing on the entire dataset</li>
<li><code class="docutils literal notranslate"><span class="pre">_read_data_chunk()</span></code> - reads the input data from one or more datasets.</li>
<li><code class="docutils literal notranslate"><span class="pre">_write_results_chunk()</span></code> - writes the computed results back to the file</li>
<li><code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> - Defines how to process a chunk (multiple units) of data. This allows room for
pre-processing of input data and post-processing of results if necessary. If neither are required, this function
essentially applies the parallel computation on <code class="docutils literal notranslate"><span class="pre">_map_function()</span></code>.</li>
<li><code class="docutils literal notranslate"><span class="pre">compute()</span></code> - this does the bulk of the work of (iteratively) reading a chunk of data &gt;&gt; processing in parallel
via <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> &gt;&gt; calling <code class="docutils literal notranslate"><span class="pre">write_results_chunk()</span></code> to write data. Most sub-classes, including the one
below, do not need to extend / modify this function.</li>
</ul>
</div>
<div class="section" id="recommended-pre-requisite-reading">
<h2>Recommended pre-requisite reading<a class="headerlink" href="#recommended-pre-requisite-reading" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="/../../data_format.html">Universal Spectroscopic and Imaging Data (USID) model</a></li>
<li><a class="reference external" href="./plot_h5py.html">Crash course on HDF5 and h5py</a></li>
<li>Utilities for <a class="reference external" href="./plot_hdf_utils_read.html">reading</a> and <a class="reference external" href="./plot_hdf_utils_write.html">writing</a>
h5USID files using pyUSID</li>
<li>Crash course on <a class="reference external" href="./plot_parallel_compute.html">parallel processing</a></li>
</ul>
</div>
<div class="section" id="example-problem">
<h2>Example problem<a class="headerlink" href="#example-problem" title="Permalink to this headline">¶</a></h2>
<p>For this example, we will be working with a Band Excitation Piezoresponse Force Microscopy (BE-PFM) imaging dataset
acquired from advanced atomic force microscopes. In this dataset, a spectra was collected for each position in a two
dimensional grid of spatial locations. Thus, this is a three dimensional dataset that has been flattened to a two
dimensional matrix in accordance with the USID model.</p>
<p>This example is based on the parallel computing primer where we searched for the peak of each spectra in a dataset.
While that example focused on comparing serial and parallel computing, we will focus on demonstrating the simplicity
with which such a data analysis algorithm can be formalized.</p>
<p>This example is a simplification of the pycroscopy.analysis.BESHOFitter class in our sister project - Pycroscopy.</p>
</div>
<div class="section" id="import-necessary-packages">
<h2>Import necessary packages<a class="headerlink" href="#import-necessary-packages" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">unicode_literals</span>

<span class="c1"># The package for accessing files in directories, etc.:</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Warning package in case something goes wrong</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="k">def</span> <span class="nf">install</span><span class="p">(</span><span class="n">package</span><span class="p">):</span>
    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;pip&quot;</span><span class="p">,</span> <span class="s2">&quot;install&quot;</span><span class="p">,</span> <span class="n">package</span><span class="p">])</span>
<span class="c1"># Package for downloading online files:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="c1"># This package is not part of anaconda and may need to be installed.</span>
    <span class="kn">import</span> <span class="nn">wget</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;wget not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;wget&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">wget</span>

<span class="c1"># The mathematical computation package:</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># The package used for creating and manipulating HDF5 files:</span>
<span class="kn">import</span> <span class="nn">h5py</span>

<span class="c1"># Packages for plotting:</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># the scientific function</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;./supporting_docs/&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">peak_finding</span> <span class="kn">import</span> <span class="n">find_all_peaks</span>

<span class="c1"># Finally import pyUSID:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pyUSID</span> <span class="kn">as</span> <span class="nn">usid</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;pyUSID not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;pyUSID&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pyUSID</span> <span class="kn">as</span> <span class="nn">usid</span>
</pre></div>
</div>
<p>The goal is to <strong>find the amplitude at the peak in each spectra</strong>. Clearly, the operation of finding the peak in one
spectra is independent of the same operation on another spectra. Thus, we could divide the dataset in to N parts and
use N CPU cores to compute the results much faster than it would take a single core to compute the results. Such
problems are ideally suited for making use of all the advanced functionalities in the Process class.</p>
<div class="section" id="defining-the-class">
<h3>Defining the class<a class="headerlink" href="#defining-the-class" title="Permalink to this headline">¶</a></h3>
<p>In order to solve our problem, we would need to implement a <code class="docutils literal notranslate"><span class="pre">sub-class</span></code> of pyUSID.Process or in other words -
<strong>extend pyUSID.Process</strong>. As mentioned above, the pyUSID.Process class already generalizes several important
components of data processing. We only need to extend this class by implementing the science-specific functionality.
The rest of the capabilities will be <strong>inherited</strong> from pyUSID.Process.</p>
<p>Lets think about what operations need be performed for each of the core Process functions listed above.</p>
</div>
</div>
<div class="section" id="map-function">
<h2>map_function()<a class="headerlink" href="#map-function" title="Permalink to this headline">¶</a></h2>
<p>The most important component in our new Process class is the unit computation that needs to be performed on each
spectra. <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> needs to take as input a single spectra and return the amplitude at the peak (a single
value). The <code class="docutils literal notranslate"><span class="pre">compute()</span></code> and <code class="docutils literal notranslate"><span class="pre">unit_computation()</span></code> will handle the parallelization.</p>
<p>The scipy package has a very handy function called <em>find_peaks_cwt()</em> that facilitates the search for one or more
peaks in a spectrum. We will be using a simplified function called <em>find_all_peaks()</em>.
The exact methodology for finding the peaks is not of interest for this
particular example. However, this function finds the index of 0 or more peaks in the spectra. We only expect
one peak at the center of the spectra. Therefore, we can use the <code class="docutils literal notranslate"><span class="pre">find_all_peaks()</span></code> function to find the peaks and
address those situations when too few or too many (&gt; 1) peaks are found in a single spectra. Finally, we need to use
the index of the peak to find the amplitude from the spectra.</p>
</div>
<div class="section" id="test">
<h2>test()<a class="headerlink" href="#test" title="Permalink to this headline">¶</a></h2>
<p>A useful test function should be able to find the peak amplitude for any single spectra in the dataset. So, given the
index of a pixel (provided by the user), we should perform two operations:</p>
<ul class="simple">
<li>read the spectra corresponding to that index from the HDF5 dataset</li>
<li>apply the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to this spectra and return the result.</li>
</ul>
<p>The goal here is to load the smallest necessary portion of data from the HDF5 dataset to memory and test it against
the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code></p>
</div>
<div class="section" id="create-results-datasets">
<h2>create_results_datasets()<a class="headerlink" href="#create-results-datasets" title="Permalink to this headline">¶</a></h2>
<p>Every Process involves a few tasks for this function:</p>
<ul>
<li><p class="first">the creation of a HDF5 group to hold the datasets containing the results - pyUSID.hdf_utils has a handy function
that takes care of this.</p>
</li>
<li><p class="first">storing any relevant metadata regarding this processing as attributes of the HDF5 group for provenance, traceability
, and reproducibility.</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">last_pixel</span></code> is a reserved attribute that serves as a flag indicating the last pixel that was successfully
processed and written to the results dataset. This attribute is key for resuming partial computations.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">the creation of HDF5 dataset(s) to hold the results. <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> takes a spectra (1D array) and returns the
amplitude (a single value). Thus the input dataset (position, spectra) will be reduced to (position, 1). So, we only
need to create a single empty dataset to hold the results.</p>
</li>
</ul>
<p>We just need to ensure that we have a reference to the results dataset so that we can populate it with the results.</p>
</div>
<div class="section" id="write-results-chunk">
<h2>write_results_chunk()<a class="headerlink" href="#write-results-chunk" title="Permalink to this headline">¶</a></h2>
<p>The result of <code class="docutils literal notranslate"><span class="pre">compute()</span></code> will be a list of amplitude values. All we need to do is:</p>
<ul class="simple">
<li>write the results into the HDF5 dataset</li>
<li>Set the <code class="docutils literal notranslate"><span class="pre">last_pixel</span></code> attribute to the value of the <code class="docutils literal notranslate"><span class="pre">end_pos</span></code> internal variable to indicate that pixels upto
<code class="docutils literal notranslate"><span class="pre">end_pos</span></code> were successfully processed. Should the computation be interrupted after this point, we could resume
from <code class="docutils literal notranslate"><span class="pre">end_pos</span></code> instead of starting from <code class="docutils literal notranslate"><span class="pre">0</span></code> again.</li>
<li>update the <code class="docutils literal notranslate"><span class="pre">start_pos</span></code> internal variable to guide compute() to process the next batch of positions / pixels</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PeakFinder</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">Process</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pixel_ind</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test the algorithm on a single pixel</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pixel_ind : uint</span>
<span class="sd">            Index of the pixel in the dataset that the process needs to be tested on.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># First read the HDF5 dataset to get the spectra for this pixel</span>
        <span class="n">spectra</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]</span>
        <span class="c1"># Next, apply the map function to the spectra. done!</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_function</span><span class="p">(</span><span class="n">spectra</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_results_datasets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates the datasets an Groups necessary to store the results.</span>
<span class="sd">        There are only THREE operations happening in this function:</span>
<span class="sd">        1. Creation of HDF5 group to hold results</span>
<span class="sd">        2. Writing relevant metadata to this HDF5 group</span>
<span class="sd">        3. Creation of a HDF5 dataset to hold results</span>

<span class="sd">        Please see examples on utilities for writing h5USID files for more information</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">process_name</span> <span class="o">=</span> <span class="s1">&#39;Peak_Finding&#39;</span>

        <span class="c1"># 1. create a HDF5 group to hold the results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_results_grp</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">create_results_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_name</span><span class="p">)</span>

        <span class="c1"># 2. Write relevant metadata to the group</span>
        <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_simple_attrs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_results_grp</span><span class="p">,</span>
                                        <span class="p">{</span><span class="s1">&#39;last_pixel&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="s1">&#39;find_all_peaks&#39;</span><span class="p">})</span>

        <span class="c1"># Explicitly stating all the inputs to write_main_dataset</span>
        <span class="c1"># The process will reduce the spectra at each position to a single value</span>
        <span class="c1"># Therefore, the result is a 2D dataset with the same number of positions as self.h5_main</span>
        <span class="n">results_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">results_dset_name</span> <span class="o">=</span> <span class="s1">&#39;Peak_Response&#39;</span>
        <span class="n">results_quantity</span> <span class="o">=</span> <span class="s1">&#39;Amplitude&#39;</span>
        <span class="n">results_units</span> <span class="o">=</span> <span class="s1">&#39;V&#39;</span>
        <span class="n">pos_dims</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># Reusing those linked to self.h5_main</span>
        <span class="n">spec_dims</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">write_utils</span><span class="o">.</span><span class="n">Dimension</span><span class="p">(</span><span class="s1">&#39;Empty&#39;</span><span class="p">,</span> <span class="s1">&#39;a. u.&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 3. Create an empty results dataset that will hold all the results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_results</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_main_dataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_results_grp</span><span class="p">,</span> <span class="n">results_shape</span><span class="p">,</span> <span class="n">results_dset_name</span><span class="p">,</span>
                                                          <span class="n">results_quantity</span><span class="p">,</span> <span class="n">results_units</span><span class="p">,</span> <span class="n">pos_dims</span><span class="p">,</span> <span class="n">spec_dims</span><span class="p">,</span>
                                                          <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                                          <span class="n">h5_pos_inds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="o">.</span><span class="n">h5_pos_inds</span><span class="p">,</span>
                                                          <span class="n">h5_pos_vals</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="o">.</span><span class="n">h5_pos_vals</span><span class="p">)</span>
        <span class="c1"># Note that this function automatically creates the ancillary datasets and links them.</span>

        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Finshed creating datasets&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_write_results_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Write the computed results back to the H5</span>
<span class="sd">        In this case, there isn&#39;t any more additional post-processing required</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># write the results to the file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_results</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_start_pos</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_pos</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">)</span>

        <span class="c1"># Flush the results to ensure that they have indeed been written to the file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

        <span class="c1"># update the &#39;last_pixel&#39; to indicate that the process was succesfully completed on this many positions:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_results_grp</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;last_pixel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_pos</span>

        <span class="c1"># Now update the start position</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_start_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_pos</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_map_function</span><span class="p">(</span><span class="n">spectra</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is the function that will be applied to each pixel in the dataset.</span>
<span class="sd">        It&#39;s job is to demonstrate what needs to be done for each pixel in the dataset.</span>
<span class="sd">        pyUSID.Process will handle the parallel computation and memory management</span>

<span class="sd">        As in typical scientific problems, the results from find_all_peaks() need to be</span>
<span class="sd">        post-processed</span>

<span class="sd">        In this case, the find_all_peaks() function can sometimes return 0 or more than one peak</span>
<span class="sd">        for spectra that are very noisy</span>

<span class="sd">        Knowing that the peak is typically at the center of the spectra,</span>
<span class="sd">        we return the central index when no peaks were found</span>
<span class="sd">        Or the index closest to the center when multiple peaks are found</span>

<span class="sd">        Finally once we have a single index, we need to index the spectra by that index</span>
<span class="sd">        in order to get the amplitude at that frequency.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">peak_inds</span> <span class="o">=</span> <span class="n">find_all_peaks</span><span class="p">(</span><span class="n">spectra</span><span class="p">,</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">],</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

        <span class="n">central_ind</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spectra</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">peak_inds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># too few peaks</span>
            <span class="c1"># set peak to center of spectra</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">central_ind</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">peak_inds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># too many peaks</span>
            <span class="c1"># set to peak closest to center of spectra</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">peak_inds</span> <span class="o">-</span> <span class="n">central_ind</span><span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">peak_inds</span><span class="p">[</span><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html#numpy.argmin" title="View documentation for numpy.argmin"><span class="n">np</span><span class="o">.</span><span class="n">argmin</span></a><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># normal situation</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">peak_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Finally take the amplitude of the spectra at this index</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">[</span><span class="n">val</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="comments">
<h2>Comments<a class="headerlink" href="#comments" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>The class appears to be large mainly because of comments that explain what each line of code is doing.</li>
<li>Several functions of pyUSID.Process such as <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> and <code class="docutils literal notranslate"><span class="pre">compute()</span></code> were inherited from the
pyUSID.Process class.</li>
<li>In simple cases such as this, we don’t even have to implement a function to read the data from the dataset since
pyUSID.Process automatically calculates how much of the data iss safe to load into memory. In this case, the
dataset is far smaller than the computer memory, so the entire dataset can be loaded and processed at once.</li>
<li>In this example, we did not need any pre-processing or post-processing of results but those can be implemented too
if necessary.</li>
<li>The majority of the code in this class would have to be written regardless of whether the intention is formalize the
data processing or not. In fact, we would argue that <strong>more</strong> code may need to be written than what is shown below
if one were <strong>not</strong> formalizing the data processing (data reading, parallel computing, memory management, etc.)</li>
<li>This is the simplest possible implementation of Process. Certain features such as checking for existing results and
resuming partial computations have not been shown in this example.</li>
</ul>
<div class="section" id="use-the-class">
<h3>Use the class<a class="headerlink" href="#use-the-class" title="Permalink to this headline">¶</a></h3>
<p>Now that the class has been written, it can be applied to an actual dataset.</p>
</div>
</div>
<div class="section" id="load-the-dataset">
<h2>Load the dataset<a class="headerlink" href="#load-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>In order to demonstrate this Process class, we will be using a real experimental dataset that is available on the
pyUSID GitHub project. First, lets download this file from Github:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_path</span> <span class="o">=</span> <span class="s1">&#39;temp.h5&#39;</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/pycroscopy/pyUSID/master/data/BELine_0004.h5&#39;</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">h5_path</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">h5_path</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">h5_path</span><span class="p">,</span> <span class="n">bar</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p>Lets open the file in an editable (r+) mode and look at the contents:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r+&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;File contents:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>File contents:

/
├ Measurement_000
  ---------------
  ├ Channel_000
    -----------
    ├ Bin_FFT
    ├ Bin_Frequencies
    ├ Bin_Indices
    ├ Bin_Step
    ├ Bin_Wfm_Type
    ├ Excitation_Waveform
    ├ Noise_Floor
    ├ Position_Indices
    ├ Position_Values
    ├ Raw_Data
    ├ Spatially_Averaged_Plot_Group_000
      ---------------------------------
      ├ Bin_Frequencies
      ├ Mean_Spectrogram
      ├ Spectroscopic_Parameter
      ├ Step_Averaged_Response
    ├ Spectroscopic_Indices
    ├ Spectroscopic_Values
    ├ UDVS
    ├ UDVS_Indices
</pre></div>
</div>
<p>The focus of this example is not on the data storage or formatting but rather on demonstrating our new Process class
so lets dive straight into the main dataset that requires analysis of the spectra:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_chan_grp</span> <span class="o">=</span> <span class="n">h5_file</span><span class="p">[</span><span class="s1">&#39;Measurement_000/Channel_000&#39;</span><span class="p">]</span>

<span class="c1"># Accessing the dataset of interest:</span>
<span class="n">h5_main</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">USIDataset</span><span class="p">(</span><span class="n">h5_chan_grp</span><span class="p">[</span><span class="s1">&#39;Raw_Data&#39;</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">The main dataset:</span><span class="se">\n</span><span class="s1">------------------------------------&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_main</span><span class="p">)</span>

<span class="c1"># Extract some metadata:</span>
<span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span> <span class="o">=</span> <span class="n">h5_main</span><span class="o">.</span><span class="n">pos_dim_sizes</span>
<span class="n">freq_vec</span> <span class="o">=</span> <span class="n">h5_main</span><span class="o">.</span><span class="n">get_spec_values</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1E-3</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The main dataset:
------------------------------------
&lt;HDF5 dataset &quot;Raw_Data&quot;: shape (16384, 119), type &quot;&lt;c8&quot;&gt;
located at:
        /Measurement_000/Channel_000/Raw_Data
Data contains:
        Cantilever Vertical Deflection (V)
Data dimensions and original shape:
Position Dimensions:
        X - size: 128
        Y - size: 128
Spectroscopic Dimensions:
        Frequency - size: 119
Data Type:
        complex64
</pre></div>
</div>
<div class="section" id="use-the-process-class">
<h3>Use the Process class<a class="headerlink" href="#use-the-process-class" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="instantiation">
<h2>Instantiation<a class="headerlink" href="#instantiation" title="Permalink to this headline">¶</a></h2>
<p>Note that the instantiation of the new <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> Process class only requires that we supply the main dataset on
which the computation will be performed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fitter</span> <span class="o">=</span> <span class="n">PeakFinder</span><span class="p">(</span><span class="n">h5_main</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Consider calling test() to check results before calling compute() which computes on the entire dataset and writes back to the HDF5 file
</pre></div>
</div>
</div>
<div class="section" id="id1">
<h2>test()<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>As advised, lets test the <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> on an example pixel:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span> <span class="o">=</span> <span class="mi">103</span><span class="p">,</span> <span class="mi">19</span>
<span class="n">pixel_ind</span> <span class="o">=</span> <span class="n">col_ind</span> <span class="o">+</span> <span class="n">row_ind</span> <span class="o">*</span> <span class="n">num_cols</span>

<span class="c1"># Testing is as simple as supplying a pixel index</span>
<span class="n">amplitude</span> <span class="o">=</span> <span class="n">fitter</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">pixel_ind</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, let’s visualize the results of the test:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spectra</span> <span class="o">=</span> <span class="n">h5_main</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axis</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">freq_vec</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">amplitude</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Frequency (kHz)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Amplitude (V)&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">))])</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;PeakFinder applied to pixel</span><span class="se">\n</span><span class="s1">at row: {}, col: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_process_001.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_process_001.png" />
<p>If we weren’t happy with the results, we could tweak some parameters when initializing the <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> object and try
again. However, for the sake of simplicity, we don’t have any parameters we can / want to adjust in this case. So,
lets proceed.</p>
</div>
<div class="section" id="compute">
<h2>compute()<a class="headerlink" href="#compute" title="Permalink to this headline">¶</a></h2>
<p>Now that we know that the <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> appears to be performing as expected, we can apply the amplitude finding</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_results_grp</span> <span class="o">=</span> <span class="n">fitter</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_results_grp</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Finshed creating datasets
You maybe able to abort this computation at any time and resume at a later time!
        If you are operating in a python console, press Ctrl+C or Cmd+C to abort
        If you are in a Jupyter notebook, click on &quot;Kernel&quot;&gt;&gt;&quot;Interrupt&quot;
Starting computing on 3 cores (requested 3 cores)
Finished parallel computation
Completed computation on chunk. Writing to file.
&lt;HDF5 group &quot;/Measurement_000/Channel_000/Raw_Data-Peak_Finding_000&quot; (3 members)&gt;
</pre></div>
</div>
<p>Lets take a look again at the file contents. We should be seeing a new HDF5 group called <code class="docutils literal notranslate"><span class="pre">Raw_Data-Peak_Finding_000</span></code> and
three datasets within the group. Among the datasets is <code class="docutils literal notranslate"><span class="pre">Peak_Response</span></code> that contains the peak amplitudes we are
interested in.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/
├ Measurement_000
  ---------------
  ├ Channel_000
    -----------
    ├ Bin_FFT
    ├ Bin_Frequencies
    ├ Bin_Indices
    ├ Bin_Step
    ├ Bin_Wfm_Type
    ├ Excitation_Waveform
    ├ Noise_Floor
    ├ Position_Indices
    ├ Position_Values
    ├ Raw_Data
    ├ Raw_Data-Peak_Finding_000
      -------------------------
      ├ Peak_Response
      ├ Spectroscopic_Indices
      ├ Spectroscopic_Values
    ├ Spatially_Averaged_Plot_Group_000
      ---------------------------------
      ├ Bin_Frequencies
      ├ Mean_Spectrogram
      ├ Spectroscopic_Parameter
      ├ Step_Averaged_Response
    ├ Spectroscopic_Indices
    ├ Spectroscopic_Values
    ├ UDVS
    ├ UDVS_Indices
</pre></div>
</div>
<p>Lets look at this <code class="docutils literal notranslate"><span class="pre">Peak_Response</span></code> dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_peak_amps</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">USIDataset</span><span class="p">(</span><span class="n">h5_results_grp</span><span class="p">[</span><span class="s1">&#39;Peak_Response&#39;</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">h5_peak_amps</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;HDF5 dataset &quot;Peak_Response&quot;: shape (16384, 1), type &quot;&lt;f4&quot;&gt;
located at:
        /Measurement_000/Channel_000/Raw_Data-Peak_Finding_000/Peak_Response
Data contains:
        Amplitude (V)
Data dimensions and original shape:
Position Dimensions:
        X - size: 128
        Y - size: 128
Spectroscopic Dimensions:
        Empty - size: 1
Data Type:
        float32
</pre></div>
</div>
</div>
<div class="section" id="visualize">
<h2>Visualize<a class="headerlink" href="#visualize" title="Permalink to this headline">¶</a></h2>
<p>Since <code class="docutils literal notranslate"><span class="pre">Peak_Response</span></code> is a USIDataset, we could use its ability to provide its own N dimensional form:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">amplitudes</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html#numpy.squeeze" title="View documentation for numpy.squeeze"><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span></a><span class="p">(</span><span class="n">h5_peak_amps</span><span class="o">.</span><span class="n">get_n_dim_form</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;N dimensional shape of Peak_Response: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">amplitudes</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>N dimensional shape of Peak_Response: (128, 128)
</pre></div>
</div>
<p>Finally, we can look at a map of the peak amplitude for the entire dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axis</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">amplitudes</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Peak Amplitudes&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_process_002.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_process_002.png" />
</div>
<div class="section" id="clean-up">
<h2>Clean up<a class="headerlink" href="#clean-up" title="Permalink to this headline">¶</a></h2>
<p>Finally lets close and delete the example HDF5 file</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">h5_path</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="flow-of-functions">
<h3>Flow of functions<a class="headerlink" href="#flow-of-functions" title="Permalink to this headline">¶</a></h3>
<p>By default, very few functions (<code class="docutils literal notranslate"><span class="pre">test()</span></code>, <code class="docutils literal notranslate"><span class="pre">compute()</span></code>) are exposed to users. This means that one of these
functions calls a chain of the other functions in the class.</p>
</div>
</div>
<div class="section" id="init">
<h2>init()<a class="headerlink" href="#init" title="Permalink to this headline">¶</a></h2>
<p>Instantiating the class via something like: <code class="docutils literal notranslate"><span class="pre">fitter</span> <span class="pre">=</span> <span class="pre">PeakFinder(h5_main)</span></code> happens in two parts:</p>
<ol class="arabic simple">
<li>First the subclass (<code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code>) calls the initialization function in <code class="docutils literal notranslate"><span class="pre">Process</span></code> to let it run some checks:</li>
</ol>
<blockquote>
<div><ul class="simple">
<li>Check if the provided <code class="docutils literal notranslate"><span class="pre">h5_main</span></code> is indeed a <code class="docutils literal notranslate"><span class="pre">Main</span></code> dataset</li>
<li>call <code class="docutils literal notranslate"><span class="pre">set_memory_and_cores()</span></code> to figure out how many pixels can be read into memory at any given time</li>
<li>Initialize some basic variables</li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="2">
<li>Next, the subclass continues any further validation / checks / initialization - this was not implemented for
<code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> but here are some things that can be done:<ul>
<li>Find HDF5 groups which either have partial or fully computed results already for the same parameters by calling
<code class="docutils literal notranslate"><span class="pre">check_for_duplicates()</span></code></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="id2">
<h2>test()<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>This function only calls the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> by definition</p>
</div>
<div class="section" id="id3">
<h2>compute()<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>Here is how compute() works:</p>
<ul class="simple">
<li>Check if you can return existing results for the requested computation and return if available by calling either:<ul>
<li><dl class="first docutils">
<dt><code class="docutils literal notranslate"><span class="pre">get_existing_datasets()</span></code> - reads all necessary parameters and gets references to the HDF5 datasets that should</dt>
<dd>contain the results</dd>
</dl>
</li>
<li><code class="docutils literal notranslate"><span class="pre">use_partial_computation()</span></code> - pick the first partially computed results group that was discovered by
<code class="docutils literal notranslate"><span class="pre">check_for_duplicates()</span></code></li>
</ul>
</li>
<li>call <code class="docutils literal notranslate"><span class="pre">create_results_datasets()</span></code> to create the HDF5 datasets and group objects</li>
<li>read the first chunk of data via <code class="docutils literal notranslate"><span class="pre">read_data_chunk()</span></code> into <code class="docutils literal notranslate"><span class="pre">self._data</span></code></li>
<li>Until the source dataset is fully read (<code class="docutils literal notranslate"><span class="pre">self._data</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">None</span></code>), do:<ul>
<li>call <code class="docutils literal notranslate"><span class="pre">unit_computation()</span></code> on <code class="docutils literal notranslate"><span class="pre">self._data</span></code><ul>
<li>By default <code class="docutils literal notranslate"><span class="pre">unit_computation()</span></code> just maps <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> onto <code class="docutils literal notranslate"><span class="pre">self._data</span></code></li>
</ul>
</li>
<li>call <code class="docutils literal notranslate"><span class="pre">write_results_chunk()</span></code> to write <code class="docutils literal notranslate"><span class="pre">self._results</span></code> into the HDF5 datasets</li>
<li>read the next chunk of data into <code class="docutils literal notranslate"><span class="pre">self._data</span></code></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="use-partial-computation">
<h2>use_partial_computation()<a class="headerlink" href="#use-partial-computation" title="Permalink to this headline">¶</a></h2>
<p>Not used in <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> but this function can be called to manually specify an HDF5 group containing partial
results</p>
<p>We encourage you to read the source code for more information.</p>
</div>
<div class="section" id="advanced-examples">
<h2>Advanced examples<a class="headerlink" href="#advanced-examples" title="Permalink to this headline">¶</a></h2>
<p>Please see the following pycroscopy classes to learn more about the advanced functionalities such as resuming
computations, checking of existing results, using unit_computation(), etc.:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">pycroscopy.processing.SignalFilter</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">pycroscopy.analysis.GIVBayesian</span></code></li>
</ul>
<div class="section" id="tips-and-tricks">
<h3>Tips and tricks<a class="headerlink" href="#tips-and-tricks" title="Permalink to this headline">¶</a></h3>
<p>Here we will cover a few common use-cases that will hopefully guide you in structuring your computational problem</p>
</div>
</div>
<div class="section" id="juggling-dimensions">
<h2>Juggling dimensions<a class="headerlink" href="#juggling-dimensions" title="Permalink to this headline">¶</a></h2>
<p>We intentionally chose a simple example above to quickly illustrate the main components / philosophy of the Process
class. The above example had two position dimensions collapsed into the first axis of the dataset and a single
spectroscopic dimension (<code class="docutils literal notranslate"><span class="pre">Frequency</span></code>). What if the spectra were acquired as a function of other variables such as a
<code class="docutils literal notranslate"><span class="pre">DC</span> <span class="pre">bias</span></code>? In other words, the dataset would now have N spectra per location.  In such cases, the dataset would have
2 spectroscopic dimensions: <code class="docutils literal notranslate"><span class="pre">Frequency</span></code> and <code class="docutils literal notranslate"><span class="pre">DC</span> <span class="pre">bias</span></code>. We cannot therefore simply map the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to
the data in every pixel. This is because the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> expects to work over a single spectra whereas we now
have N spectra per pixel. Contrary to what one would assume, we do not need to throw away all the code we wrote above.
We only need to add code to juggle / move the dimensions around till the problem looks similar to what we had above.</p>
<p>In other words, the above problem was written for a dataset of shape <code class="docutils literal notranslate"><span class="pre">(P,</span> <span class="pre">S)</span></code> where <code class="docutils literal notranslate"><span class="pre">P</span></code> is the number of positions
and <code class="docutils literal notranslate"><span class="pre">S</span></code> is the length of a single spectra. Now, we have data of shape <code class="docutils literal notranslate"><span class="pre">(P,</span> <span class="pre">N*S)</span></code> where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of
spectra per position. In order to use most of the code already written above, we need to reshape the data to the shape
<code class="docutils literal notranslate"><span class="pre">(P*N,</span> <span class="pre">S)</span></code>. Now, we can easily map the existing <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> on this <code class="docutils literal notranslate"><span class="pre">(P*N,</span> <span class="pre">S)</span></code> dataset.</p>
<p>As far as implementation is concerned, we would need to add the reshaping step to <code class="docutils literal notranslate"><span class="pre">_read_data_chunk()</span></code> as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_read_data_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PeakFinder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_read_data_chunk</span><span class="p">()</span>
    <span class="c1"># The above line causes the base Process class to read X pixels from the dataset into self.data</span>
    <span class="c1"># All we need to do now is reshape self.data from (X, N*S) to (X*N, S):</span>
    <span class="c1"># Assuming that we know N (num_spectra) through some metadata:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">num_spectra</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Recall that <code class="docutils literal notranslate"><span class="pre">_read_data_chunk()</span></code> reads <code class="docutils literal notranslate"><span class="pre">X</span></code> pixels at a time where <code class="docutils literal notranslate"><span class="pre">X</span></code> is the largest number of pixels whose raw
data, intermediate products, and results can simultaneously be held in memory. The dataset used for the example above
is tractable enough that the entire data is loaded at once, meaning that <code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">P</span></code> in this case.</p>
<p>From here, on, the computation would continue as is but as expected, the results would also consequently be of shape
<code class="docutils literal notranslate"><span class="pre">(P*N)</span></code>. We would have to reverse the reshape operation to get back the results in the form: <code class="docutils literal notranslate"><span class="pre">(P,</span> <span class="pre">N)</span></code>. So we
would prepend the reverse reshape operation to <code class="docutils literal notranslate"><span class="pre">_write_results_chunk()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_write_results_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Recall that the results from the computation are stored in a list called self._results</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_results</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="View documentation for numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">)</span>  <span class="c1"># convert from list to numpy array</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_spectra</span><span class="p">)</span>
    <span class="c1"># Now self._results is of shape (P, N) and we can store it in the HDF5 dataset as we did above.</span>
</pre></div>
</div>
</div>
<div class="section" id="computing-on-chunks-instead-of-mapping">
<h2>Computing on chunks instead of mapping<a class="headerlink" href="#computing-on-chunks-instead-of-mapping" title="Permalink to this headline">¶</a></h2>
<p>In certain cases, the computation is a little more complex that the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> cannot directly be mapped to
the data. Alternatively, in some cases the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> needs to mapped multiple times or different sections of
the <code class="docutils literal notranslate"><span class="pre">self.data</span></code>. For such cases, the <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> in <code class="docutils literal notranslate"><span class="pre">Process</span></code> provides far more flexibility to the
developer. Please see the <code class="docutils literal notranslate"><span class="pre">pycroscopy.processing.SignalFilter</span></code> and <code class="docutils literal notranslate"><span class="pre">pycroscopy.analysis.GIVBayesian</span></code> for examples.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> maps the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to <code class="docutils literal notranslate"><span class="pre">self.data</span></code> using <code class="docutils literal notranslate"><span class="pre">parallel_compute()</span></code> and
stores the results in <code class="docutils literal notranslate"><span class="pre">self._results</span></code>. Recall that <code class="docutils literal notranslate"><span class="pre">self.data</span></code> contains data for <code class="docutils literal notranslate"><span class="pre">X</span></code> pixels.
For example, <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> in <code class="docutils literal notranslate"><span class="pre">pycroscopy.analysis.GIVBayesian</span></code> breaks up the spectra (second axis) of
<code class="docutils literal notranslate"><span class="pre">self.data</span></code> into two halves and computes the results separately for each half. <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> for this
class calls <code class="docutils literal notranslate"><span class="pre">parallel_compute()</span></code> twice - to map the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to each half of the data chunk. This is a
functionality that is challenging to efficiently attain without <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code>. Note that when the
<code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> is overridden, the developer is responsible for the correct usage of <code class="docutils literal notranslate"><span class="pre">parallel_compute()</span></code>,
especially passing arguments and keyword arguments.</p>
</div>
<div class="section" id="other-notes">
<h2>Other Notes<a class="headerlink" href="#other-notes" title="Permalink to this headline">¶</a></h2>
<p>We are exploring Dask as a framework for embarrassingly parallel computation.</p>
<p><strong>Total running time of the script:</strong> ( 0 minutes  37.397 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-cookbooks-plot-process-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_process.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_process.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_process.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_process.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="plot_io_utils.html" class="btn btn-neutral float-right" title="11. Input / Output / Computing utilities" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="plot_hdf_utils_write.html" class="btn btn-neutral" title="09. Utilities for writing h5USID files" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Suhas Somnath, Chris R. Smith, Stephen Jesse.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.0.4',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>