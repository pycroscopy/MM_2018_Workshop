{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n================================================================================\n02. The USIDataset\n================================================================================\n\n**Suhas Somnath**\n\n11/11/2017\n\n**This document illustrates how the pyUSID.USIDataset class substantially simplifies accessing information about,\nslicing, and visualizing N-dimensional Universal Spectroscopy and Imaging Data (USID) Main datasets**\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "USID Main Datasets\n------------------\nAccording to the **Universal Spectroscopy and Imaging Data (USID)** model, all spatial dimensions are collapsed to a\nsingle dimension and, similarly, all spectroscopic dimensions\nare also collapsed to a single dimension. Thus, the data is stored as a two-dimensional (N x P) matrix with N spatial\nlocations each with P spectroscopic data points.\n\nThis general and intuitive format allows imaging data from any instrument, measurement scheme, size, or dimensionality\nto be represented in the same way. Such an instrument independent data format enables a single set of analysis and\nprocessing functions to be reused for multiple image formats or modalities.\n\n``Main datasets`` are greater than the sum of their parts. They are more capable and information-packed than\nconventional datasets since they have (or are linked to) all the necessary information to describe a measured dataset.\nThe additional information contained / linked by ``Main datasets`` includes:\n\n* the recorded physical quantity\n* units of the data\n* names of the position and spectroscopic dimensions\n* dimensionality of the data in its original N dimensional form etc.\n\nUSIDatasets = USID Main Datasets\n--------------------------------\nRegardless, ``Main datasets`` are just concepts or blueprints and not concrete digital objects in a programming language\nor a file. ``USIDatasets`` are **tangible representations of Main datasets**. From an implementation perspective, the\nUSIDataset class extends the ``h5py.Dataset object``. In other words, USIDatasets have all the capabilities of\nstandard HDF5 / h5py Dataset objects but are supercharged from a scientific perspective since they:\n\n* are self-describing\n* allow quick interactive visualization in Jupyter notebooks\n* allow intuitive slicing of the N dimensional dataset\n* and much much more.\n\nWhile it is most certainly possible to access this information and enable these functionalities via the native ``h5py``\nfunctionality, it can become tedious very quickly.  In fact, a lot of the functionality of USIDataset comes from\norchestration of multiple functions in ``pyUSID.hdf_utils`` outlined in other documents. The USIDataset class\nmakes such necessary information and functionality easily accessible.\n\nSince Main datasets are the hubs of information in a USID HDF5 file (**h5USID**), we expect that the majority of\nthe data interrogation will happen via USIDatasets\n\nRecommended pre-requisite reading\n---------------------------------\n* `USID data model </../../data_format.html>`_\n* `Crash course on HDF5 and h5py <./plot_h5py.html>`_\n* Utilities for `reading <./plot_hdf_utils_read.html>`_ and `writing <./plot_hdf_utils_write.html>`_\n  h5USID files using pyUSID\n\nExample scientific dataset\n---------------------------\n\nBefore, we dive into the functionalities of USIDatasets we need to understand the dataset that will be used in this\nexample. For this example, we will be working with a Band Excitation Polarization Switching (BEPS) dataset acquired\nfrom advanced atomic force microscopes. In the much simpler Band Excitation (BE) imaging datasets, a single spectra\nis acquired at each location in a two dimensional grid of spatial locations. Thus, BE imaging datasets have two\nposition dimensions (X, Y) and one spectroscopic dimension (frequency - against which the spectra is recorded). The\nBEPS dataset used in this example has a spectra for each combination of three other parameters (DC offset, Field, and\nCycle). Thus, this dataset has three new spectral dimensions in addition to the spectra itself. Hence, this dataset\nbecomes a 2+4 = 6 dimensional dataset\n\nLoad all necessary packages\n---------------------------\n\nFirst, we need to load the necessary packages. Here are a list of packages, besides pyUSID, that will be used in\nthis example:\n\n* ``h5py`` - to open and close the file\n* ``wget`` - to download the example data file\n* ``numpy`` - for numerical operations on arrays in memory\n* ``matplotlib`` - basic visualization of data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division, unicode_literals\nimport os\n# Warning package in case something goes wrong\nfrom warnings import warn\nimport subprocess\nimport sys\n\n\ndef install(package):\n    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", package])\n# Package for downloading online files:\n\n\ntry:\n    # This package is not part of anaconda and may need to be installed.\n    import wget\nexcept ImportError:\n    warn('wget not found.  Will install with pip.')\n    import pip\n    install('wget')\n    import wget\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\ntry:\n    import pyUSID as usid\nexcept ImportError:\n    warn('pyUSID not found.  Will install with pip.')\n    import pip\n    install('pyUSID')\n    import pyUSID as usid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the dataset\n-----------------\nFirst, lets download example h5USID file from the pyUSID Github project:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/pycroscopy/pyUSID/master/data/BEPS_small.h5'\nh5_path = 'temp.h5'\n_ = wget.download(url, h5_path, bar=None)\n\nprint('Working on:\\n' + h5_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, lets open this HDF5 file in read-only mode. Note that opening the file does not cause the contents to be\nautomatically loaded to memory. Instead, we are presented with objects that refer to specific HDF5 datasets,\nattributes or groups in the file\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_path = 'temp.h5'\nh5_f = h5py.File(h5_path, mode='r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, ``h5_f`` is an active handle to the open file.\nLets quickly look at the contents of this HDF5 file using a handy function in ``pyUSID.hdf_utils`` - ``print_tree()``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Contents of the H5 file:')\nusid.hdf_utils.print_tree(h5_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this example, we will only focus on the ``Raw_Data`` dataset which contains the 6D raw measurement data. First lets\naccess the HDF5 dataset and check if it is a ``Main`` dataset in the first place:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_raw = h5_f['/Measurement_000/Channel_000/Raw_Data']\nprint(h5_raw)\nprint('h5_raw is a main dataset? {}'.format(usid.hdf_utils.check_if_main(h5_raw)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It turns out that this is indeed a Main dataset. Therefore, we can turn this in to a USIDataset without any\nproblems.\n\nCreating a USIDataset\n-----------------------\nAll one needs for creating a USIDataset object is a Main dataset. Here is how we can supercharge h5_raw:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pd_raw = usid.USIDataset(h5_raw)\nprint(pd_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how easy it was to create a USIDataset object. Also, note how the USIDataset is much more informative in\ncomparison with the conventional h5py.Dataset object.\n\nUSIDataset = Supercharged(h5py.Dataset)\n=========================================\nRemember that USIDataset is just an extension of the h5py.Dataset object class. Therefore, both the ``h5_raw`` and\n``pd_raw`` refer to the same object as the following equality test demonstrates. Except ``pd_raw`` knows about the\n``ancillary datasets`` and other information which makes it a far more powerful object for you.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(pd_raw == h5_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Easier access to information\n----------------------------\nSince the USIDataset is aware and has handles to the supporting ancillary datasets, they can be accessed as\nproperties of the object unlike HDF5 datasets. Note that these ancillary datasets can be accessed using functionality\nin pyUSID.hdf_utils as well. However, the USIDataset option is far easier.\n\nLet us compare accessing the Spectroscopic Indices via the USIDataset and hdf_utils functionality:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_spec_inds_1 = pd_raw.h5_spec_inds\nh5_spec_inds_2 = usid.hdf_utils.get_auxiliary_datasets(h5_raw, 'Spectroscopic_Indices')[0]\nprint(h5_spec_inds_1 == h5_spec_inds_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the same vein, it is also easy to access **string descriptors** of the ancillary datasets and the Main dataset.\nThe ``hdf_utils`` alternatives to these operations / properties also exist and are discussed in an alternate document,\nbut will not be discussed here for brevity.:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Desctiption of physical quantity in the Main dataset:')\nprint(pd_raw.data_descriptor)\nprint('Position Dimension names and sizes:')\nfor name, length in zip(pd_raw.pos_dim_labels, pd_raw.pos_dim_sizes):\n    print('{} : {}'.format(name, length))\nprint('Spectroscopic Dimension names and sizes:')\nfor name, length in zip(pd_raw.spec_dim_labels, pd_raw.spec_dim_sizes):\n    print('{} : {}'.format(name, length))\nprint('Position Dimensions:')\nprint(pd_raw.pos_dim_descriptors)\nprint('Spectroscopic Dimensions:')\nprint(pd_raw.spec_dim_descriptors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Values for each Dimension\n-------------------------\nWhen visualizing the data it is essential to plot the data against appropriate values on the X, Y, Z axes. The\nUSIDataset object makes it very easy to access the values over which a dimension was varied using the\n``get_pos_values()`` and ``get_spec_values()`` functions. This functionality is enabled by the ``get_unit_values()``\nfunction in ``pyUSID.hdf_utils``.\n\nFor example, let us say we wanted to see how the ``DC_Offset`` dimension was varied, we could:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dim_name = 'DC_Offset'\ndc_vec = pd_raw.get_spec_values(dim_name)\nfig, axis = plt.subplots(figsize=(3.5, 3.5))\naxis.plot(dc_vec)\naxis.set_xlabel('Points in dimension')\naxis.set_title(dim_name)\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reshaping to N dimensions\n-------------------------\n\nThe USID model stores N dimensional datasets in a flattened 2D form of position x spectral values. It can become\nchallenging to retrieve the data in its original N-dimensional form, especially for multidimensional datasets\nsuch as the one we are working on. Fortunately, all the information regarding the dimensionality of the dataset\nare contained in the spectral and position ancillary datasets. PycoDataset makes it remarkably easy to obtain the N\ndimensional form of a dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ndim_form = pd_raw.get_n_dim_form()\nprint('Shape of the N dimensional form of the dataset:')\nprint(ndim_form.shape)\nprint('And these are the dimensions')\nprint(pd_raw.n_dim_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Slicing\n-------\nIt is often very challenging to grapple with multidimensional datasets such as the one in this example. It may not\neven be possible to load the entire dataset in its 2D or N dimensional form to memory if the dataset is several (or\nseveral hundred) gigabytes large. Slicing the 2D Main dataset can easily become confusing and frustrating. To solve\nthis problem, USIDataset has a ``slice()`` function that efficiently loads the only the sliced data into memory and\nreshapes the data to an N dimensional form. Best of all, the slicing arguments can be provided in the actual\nN dimensional form!\n\nFor example, imagine that we cannot load the entire example dataset in its N dimensional form and then slice it. Lets\ntry to get the spatial map for the following conditions without loading the entire dataset in its N dimensional form\nand then slicing it :\n\n* 14th index of DC Offset\n* 1st index of cycle\n* 0th index of Field (remember Python is 0 based)\n* 43rd index of Frequency\n\nTo get this, we would slice as:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spat_map_1, success = pd_raw.slice({'Frequency': 43, 'DC_Offset': 14, 'Field': 0, 'Cycle': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a verification, lets try to plot the same spatial map by slicing the N dimensional form we got earlier and compare\nit with what we got above:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spat_map_2 = np.squeeze(ndim_form[:, :, 43, 14, 0, 1])\nprint('2D slicing == ND slicing: {}'.format(np.allclose(spat_map_1, spat_map_2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interactive Visualization\n---------------------------\nUSIDatasets also enable quick, interactive, and easy visualization of data up to 2 position and 2 spectroscopic\ndimensions (4D datasets). Since this particular example has 6 dimensions, we would need to slice two dimensions in\norder to visualize the remaining 4 dimensions. Note that this interactive visualization ONLY works on Jupyter\nNotebooks. This html file generated by a python script does not allow for interactive visualization and you may only\nsee a set of static plots. We encourage you to click on the\n`Download as Jupyter Notebook <https://pycroscopy.github.io/pyUSID/_downloads/plot_usi_dataset.ipynb>`_ button\nbelow to try it out yourself.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pd_raw.visualize(slice_dict={'Field': 0, 'Cycle': 1});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Close and delete the h5_file\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_f.close()\nos.remove(h5_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}