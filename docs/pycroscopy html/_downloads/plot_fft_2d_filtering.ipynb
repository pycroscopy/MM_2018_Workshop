{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n======================================================================================\nFFT & Filtering of Atomically Resolved Images\n======================================================================================\n\n**Stephen Jesse and Suhas Somnath**\n\n* Institute for Functional Imaging of Materials\n* Center for Nanophase Materials Sciences\n\nOak Ridge National Laboratory, Oak Ridge TN 37831, USA\n\n9/28/2015\n\nFourier transforms offer a very fast and convenient means to analyze and filter \nmultidimensional data including images. The power of the Fast Fourier Transform \n(FFT) is due in part to (as the name suggests) its speed and also to the fact that \ncomplex operations such as convolution and differentiation/integration are made much \nsimpler when performed in the Fourier domain. For instance, convolution in the real \nspace domain can be performed using multiplication in the Fourier domain, and \ndifferentiation/integration in the real space domain can be performed by \nmultiplying/dividing by i\u03c9 in the Fourier domain (where \u03c9 is the transformed variable). \nWe will take advantage of these properties and demonstrate simple image filtering and \nconvolution with example.   \n\nA few properties/uses of FFT\u2019s are worth reviewing.\n\nIn this example we will load an image, Fourier transform it, apply a smoothing filter, and transform it back.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import division, unicode_literals, print_function\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.fft as npf\nimport os\nimport subprocess\nimport sys\n\ndef install(package):\n    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", package])\n# for downloading files:\ntry:\n    # This package is not part of anaconda and may need to be installed.\n    import wget\nexcept ImportError:\n    print('wget not found.  Will install with pip.')\n    import pip\n    install('wget')\n    import wget\ntry:\n    import pyUSID as usid\nexcept ImportError:\n    print('pyUSID not found.  Will install with pip.')\n    import pip\n    install('pyUSID')\n    import pyUSID as usid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will be using an image available on our GitHub project page by default. You are encouraged\nto download this document as a Jupyter Notebook (button at the bottom of the page) and use your own image instead.\nWhen using your own image, you can skip this cell and provide the path to your data using the variable -\ndata_file_path\n\nComing back to our example, lets start by downloading the file from GitHub:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_file_path = 'temp_STEM_STO.txt'\n# download the data file from Github:\nurl = 'https://raw.githubusercontent.com/pycroscopy/pycroscopy/master/data/STEM_STO_2_20.txt'\n_ = wget.download(url, data_file_path, bar=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image is stored as a tab delimited text file. One can load its contents to memory by using the following command:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image_raw = np.loadtxt(data_file_path, dtype='str', delimiter='\\t')\n\n# delete the temporarily downloaded file:\nos.remove(data_file_path)\n\n# convert the file from a string array to a numpy array of floating point numbers\nimage_raw = np.array(image_raw)\nimage_raw = image_raw[0:, 0:-1].astype(np.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prior to transforming, it is sometimes convenient to set the image mean to zero, \nbecause if the mean value of an image is large, the magnitude of the zero-frequency \nbin can dominate over the other signals of interest. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image_raw = image_raw - np.mean(image_raw)  # subtract out the mean of the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An important aspect of performing Fourier transforms is keeping track of units \nbetween transformations and also being aware of conventions used with regard to\nthe locations of the image centers and extents when transformed. Below is code \nthat builds the axes in the space domain of the original image. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_pixels, y_pixels = np.shape(image_raw)  # [pixels]\nx_edge_length = 5.0  # [nm]\ny_edge_length = 5.0  # [nm]\nx_sampling = x_pixels / x_edge_length  # [pixels/nm]\ny_sampling = y_pixels / y_edge_length  # [pixels/nm]\nx_axis_vec = np.linspace(-x_edge_length / 2, x_edge_length / 2, x_pixels)  # vector of locations along x-axis\ny_axis_vec = np.linspace(-y_edge_length / 2, y_edge_length / 2, y_pixels)  # vector of locations along y-axis\nx_mat, y_mat = np.meshgrid(x_axis_vec, y_axis_vec)  # matrices of x-positions and y-positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, the axes in the Fourier domain are defined below. Note, that since \nthe number of pixels along an axis is even, a convention must be followed as to \nwhich side of the halfway point the zero-frequency bin is located. In Matlab, the \nzero frequency bin is located to the left of the halfway point. Therefore the axis \nextends from -\u03c9_sampling/2 to one frequency bin less than +\u03c9_sampling/2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "u_max = x_sampling / 2\nv_max = y_sampling / 2\nu_axis_vec = np.linspace(-u_max / 2, u_max / 2, x_pixels)\nv_axis_vec = np.linspace(-v_max / 2, v_max / 2, y_pixels)\nu_mat, v_mat = np.meshgrid(u_axis_vec, v_axis_vec)  # matrices of u-positions and v-positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A plot of the data is shown below (STEM image of STO).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axis = plt.subplots(figsize=(5, 5))\n_ = usid.plot_utils.plot_map(axis, image_raw, cmap=plt.cm.inferno, clim=[0, 6],\n                           x_vec=x_axis_vec, y_vec=y_axis_vec, num_ticks=5)\naxis.set_title('original image of STO captured via STEM')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Fourier transform can be determined with one line of code:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fft_image_raw = npf.fft2(image_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the magnitude 2D-FFT on a vertical log scales shows something unexpected:\nthere appears to be peaks at the corners and no information at the center. \nThis is because the output for the \u2018fft2\u2019 function flips the frequency axes so \nthat low frequencies are at the ends, and the highest frequency is in the middle. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axis = plt.subplots(figsize=(5, 5))\n_ = usid.plot_utils.plot_map(axis, np.abs(fft_image_raw), cmap=plt.cm.OrRd, clim=[0, 3E+3])\naxis.set_title('FFT2 of image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To correct this, use the \u2018fftshift\u2019 command. \nfftshift brings the lowest frequency components of the FFT back to the center of the plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fft_image_raw = npf.fftshift(fft_image_raw)\nfft_abs_image_raw = np.abs(fft_image_raw)\n\n\ndef crop_center(image, cent_size=128):\n    return image[image.shape[0]//2 - cent_size // 2: image.shape[0]//2 + cent_size // 2,\n                 image.shape[1]//2 - cent_size // 2: image.shape[1]//2 + cent_size // 2]\n\n\n# After the fftshift, the FFT looks right\nfig, axes = plt.subplots(ncols=2, figsize=(10, 5))\nfor axis, img, title in zip(axes, [fft_abs_image_raw, crop_center(fft_abs_image_raw)], ['FFT after fftshift-ing',\n                                                                                        'Zoomed view around origin']):\n    _ = usid.plot_utils.plot_map(axis, img, cmap=plt.cm.OrRd, clim=[0, 1E+4])\n    axis.set_title(title)\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first filter we want to make is a 2D, radially symmetric, low-pass Gaussian filter. \nTo start with, it is helpful to redefine the Fourier domain in polar coordinates to make\nbuilding the radially symmetric function easier. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r = np.sqrt(u_mat**2+v_mat**2) # convert cartesian coordinates to polar radius"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An expression for the filter is given below. Note, the width of the filter is defined in\nterms of the real space dimensions for ease of use.  \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filter_width = .15  # inverse width of gaussian, units same as real space axes\ngauss_filter = np.e**(-(r*filter_width)**2)\n\nfig, axes = plt.subplots(ncols=2, figsize=(10, 5))\n_ = usid.plot_utils.plot_map(axes[0], gauss_filter, cmap=plt.cm.OrRd)\naxes[0].set_title('Gaussian filter')\naxes[1].plot(gauss_filter[gauss_filter.shape[0]//2])\naxes[1].set_title('Cross section of filter')\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Application of the filter to the data in the Fourier domain is done simply by \ndot-multiplying the two matrices.  \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "F_m1_filtered = gauss_filter * fft_image_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To view the filtered data in the space domain, simply use the inverse fast Fourier transform\n(\u2018ifft2\u2019). Remember though that python expects low frequency components at the corners, so \nit is necessary to use the inverse of the \u2018fftshift\u2019 command (\u2018ifftshift\u2019) before performing\nthe inverse transform. Also, note that even though theoretically there should be no imaginary\ncomponents in the inverse transformed data (because we multiplied two matrices together that\nwere both symmetric about 0), some of the numerical manipulations create small round-off \nerrors that result in the inverse transformed data being complex (the imaginary component is\n~1X1016  times smaller than the real part). In order to account for this, only the real part\nof the result is kept.    \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image_filtered = npf.ifft2(npf.ifftshift(F_m1_filtered))\nimage_filtered = np.real(image_filtered)\n\nfig, axes = plt.subplots(ncols=2, figsize=(10, 5))\nfor axis, img, title in zip(axes, [image_raw, image_filtered], ['original', 'filtered']):\n    _ = usid.plot_utils.plot_map(axis, img, cmap=plt.cm.inferno,\n                               x_vec=x_axis_vec, y_vec=y_axis_vec, num_ticks=5)\n    axis.set_title(title)\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filtering can also be used to help flatten an image. To demonstrate this, let\u2019s artificially\nadd a background to the original image, and later try to remove it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "background_distortion = 0.2 * (x_mat + y_mat + np.sin(2 * np.pi * x_mat / x_edge_length))\nimage_w_background = image_raw + background_distortion\n\nfig, axes = plt.subplots(figsize=(10, 5), ncols=2)\nfor axis, img, title in zip(axes, [background_distortion, image_w_background], ['background', 'image with background']):\n    _ = usid.plot_utils.plot_map(axis, img, cmap=plt.cm.inferno,\n                               x_vec=x_axis_vec, y_vec=y_axis_vec, num_ticks=5)\n    axis.set_title(title)\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since large scale background distortions (such as tilting and bowing) are primarily low\nfrequency information. We can make a filter to get rid of the lowest frequency components. \nHere we again use a radially symmetric 2D Gaussian, however in this case we invert it so \nthat it is zero at low frequencies and 1 at higher frequencies.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filter_width = 2  # inverse width of gaussian, units same as real space axes\ninverse_gauss_filter = 1-np.e**(-(r*filter_width)**2)\n\nfig, axis = plt.subplots()\n_ = usid.plot_utils.plot_map(axis, inverse_gauss_filter, cmap=plt.cm.OrRd)\naxis.set_title('background filter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's perform the same process of taking the FFT of the image, multiplying with the filter\nand taking the inverse Fourier transform of the image to get the filtered image. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# take the fft of the image\nfft_image_w_background = npf.fftshift(npf.fft2(image_w_background))\nfft_abs_image_background = np.abs(fft_image_w_background)\n\n# apply the filter\nfft_image_corrected = fft_image_w_background * inverse_gauss_filter\n\n# perform the inverse fourier transform on the filtered data\nimage_corrected = np.real(npf.ifft2(npf.ifftshift(fft_image_corrected)))\n\n# find what was removed from the image by filtering\nfiltered_background = image_w_background - image_corrected\n\nfig, axes = plt.subplots(ncols=2, figsize=(10, 5))\nfor axis, img, title in zip(axes, [image_corrected, filtered_background],\n                            ['image with background subtracted', \n                             'background component that was removed']):\n    _ = usid.plot_utils.plot_map(axis, img, cmap=plt.cm.inferno,\n                               x_vec=x_axis_vec, y_vec=y_axis_vec, num_ticks=5)\n    axis.set_title(title)\nfig.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}